{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 분석 및 모델 생성 코드 분석"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 항해 선박 이동 경로 빅데이터 /AI 예측 웹 서비스\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 요약\n",
    "해당 문서는 항해 선박 이동 경로 빅데이터 /AI 예측 웹 서비스를 위해 위해 만든 데이터셋을 분석하는 과정과, 데이터 모델 제작에 관한 코드를 모아 놓은 보고서입니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  목적\n",
    "AIS 데이터는 선박의 속도에 따라 동적 정보(위치,속도,코스)의 전송 주기(Reporting Time)가 정해져 있으므로 전송 주기 사이에 존재하는 선박의 위치는 바로 직전의 정보를 물리 계산식을 통해 단순예측할 수 밖에 없음. AIS 및 해양기상데이터를 학습하여 전송 구간 사이에 최적의 선박위치를 웹서비스로 표출  \n",
    "- 입력 데이터 : AIS 데이터, 해양 기상 데이터(풍향, 풍속, 파고, 유향, 유속, 기온 ...)\n",
    "- 출력 데이터 : 해당 선박의 현재 경위도 좌표, 속도,방향\n",
    "- 제한 : 여러 선박 종류들 중에서 2가지로 한정(어선, 화물선, 여객선 등), 선박의 크기(가로, 세로) 한정  \n",
    "\n",
    "### 요구사항 \n",
    " 1.  수신되는 신호를 기반으로 선박들의 현재 위치를 전시\n",
    " 2.  5분이 지나도 신호가 수신되지 않는 선박에 대해서는 위치를 예측하여 전시.\n",
    " 3.  다시 신호가 들어오면 해당 신호의 위치를 표출\n",
    " 4.  AIS 소실 시 항해 경로를 예측하여 예측한 데이터를 지도에 표시\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.데이터 수집 및 분석,전처리 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1) AIS 데이터 분석\n",
    "- 소스데이터 세트 (GC / 건수):(초)당 실시간으로 들어오는 AIS 데이터에서의 mmis(해상이동업무식별번호),ship_name,ship_type,time,위도,cog,sog,경도 정보 관련 GC(AIS)데이터를 분석,결측치 및 이상치를 확인 후 해당사항 처리\n",
    "\n",
    "- time:1683613053941 mmsi:440135000 shipType:90 shipName:SAE NURI posX:129.3960644030396 posY:34.85181069187095\n",
    "time:1683613054216 mmsi:273353060 shipType:0 shipName: posX:129.32199830786394 posY:34.95489321184083\n",
    "time:1683613054441 mmsi:413996000 shipType:0 shipName: posX:129.16234073241736 posY:34.893753305348206\n",
    "time:1683613055009 mmsi:636092792 shipType:0 shipName: posX:129.68934637699894 posY:35.0224762771314\n",
    "time:1683613055989 mmsi:440105680 shipType:0 shipName: posX:129.39939715274366 posY:34.98919584890286\n",
    "time:1683613056111 mmsi:440067880 shipType:0 shipName: posX:129.2775676339114 posY:34.95364155652375\n",
    "time:1683613056433 mmsi:440120421 shipType:0 shipName: posX:129.18929019094097 posY:34.89292807288728\n",
    "time:1683613056683 mmsi:440061280 shipType:0 shipName: posX:129.18451115362944 posY:35.016686470294616\n",
    "time:1683613057125 mmsi:477326200 shipType:0 shipName: posX:129.24631524517685 posY:34.98871747743862\n",
    "time:1683613057191 mmsi:241632000 shipType:89 shipName:SEA DOLPHIN posX:129.43364991452717 posY:35.03885030886937\n",
    "time:1683613057628 mmsi:636022727 shipType:82 shipName:TRADER III posX:129.33268825974497 posY:34.8882344056207\n",
    "time:1683613057748 mmsi:440154010 shipType:0 shipName: posX:129.1809897577157 posY:35.01581097462178\n",
    "time:1683613057810 mmsi:229047000 shipType:70 shipName:JETSTREAM posX:129.24625236310698 posY:34.864909461679545\n",
    "time:1683613057952 mmsi:311698000 shipType:0 shipName: posX:129.25571162304877 posY:34.8516632543422\n",
    "time:1683613058486 mmsi:357104000 shipType:0 shipName: posX:129.6675712145119 posY:35.099676161538746\n",
    "time:1683613058851 mmsi:440135000 shipType:90 shipName:SAE NURI posX:129.396324914472 posY:34.85204659136741\n",
    "time:1683613059332 mmsi:273394340 shipType:70 shipName:PATRIA posX:129.50196679188446 posY:34.921091810459636\n",
    "time:1683613060707 mmsi:511100559 shipType:0 shipName: posX:129.33936274230595 posY:34.97639660933228\n",
    "time:1683613060983 mmsi:477832100 shipType:0 shipName: posX:129.94774676847592 posY:35.03793091962549\n",
    "time:1683613061411 mmsi:352001904 shipType:0 shipName: posX:129.2705428083896 posY:34.92490713215991 ......"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  해당 실시간 AIS데이터를 postgis를 이용하여 csv파일로 해당 데이터 가져오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mmsi      ship_name  ship_type   \n",
      "0      440051540           D-01          0  \\\n",
      "1      440300780            NaN          0   \n",
      "2      440208550            NaN          0   \n",
      "3      440275000  GBK EXPRESS 1         40   \n",
      "4      440414850   NO1 GEO SUNG         80   \n",
      "...          ...            ...        ...   \n",
      "16180  538010219  SAWASDEE VEGA         70   \n",
      "16181  440121850            NaN          0   \n",
      "16182  440110850  PILOT ORYUKDO         50   \n",
      "16183  440107840   NO.7 GEUMHWA         30   \n",
      "16184  440134620       HYUNJUNG         80   \n",
      "\n",
      "                                                    geom    cog   sog   \n",
      "0      0101000020110F00000000002039676B41000000002DCF...  329.2   5.7  \\\n",
      "1      0101000020110F0000000000C0D2666B410000008079E5...  329.8   0.0   \n",
      "2      0101000020110F00000000002062656B4100000080F0DD...  139.3   0.0   \n",
      "3      0101000020110F000000000040A1666B41000000800AE4...  175.8   0.0   \n",
      "4      0101000020110F00000000004097666B410000008067E5...    0.0   0.0   \n",
      "...                                                  ...    ...   ...   \n",
      "16180  0101000020110F0000000000C0DC636B41000000009893...  225.2  16.0   \n",
      "16181  0101000020110F00000000002040656B410000008050DC...    0.0   0.0   \n",
      "16182  0101000020110F0000000000E057696B4100000080C5D8...  322.3   1.7   \n",
      "16183  0101000020110F0000000000003A656B410000000047DC...    0.0   0.0   \n",
      "16184  0101000020110F0000000000609A666B41000000003CE5...  231.3   0.7   \n",
      "\n",
      "                  insert_time  \n",
      "0     2023-05-11 10:10:58.000  \n",
      "1     2023-05-11 10:10:58.000  \n",
      "2     2023-05-11 10:10:58.000  \n",
      "3     2023-05-11 10:10:58.000  \n",
      "4     2023-05-11 10:10:58.000  \n",
      "...                       ...  \n",
      "16180 2023-05-11 10:29:59.388  \n",
      "16181 2023-05-11 10:29:59.689  \n",
      "16182 2023-05-11 10:29:59.800  \n",
      "16183 2023-05-11 10:29:59.855  \n",
      "16184 2023-05-11 10:30:00.000  \n",
      "\n",
      "[16185 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df = 'D:/장우영/LOCALSEARCH\\DA\\DA\\data/Ais_Test.xlsx'\n",
    "ais_data = pd.read_excel(df)\n",
    "print(ais_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/AIS%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%9D%B4%EB%AF%B8%EC%A7%80.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) 기상청 데이터 분석\n",
    "-국립 해양측위정보원에서의 실시간  해양기상 통계자료 중 선박 이동 경로에 영향을 미치는 기상 요인(예:풍향, 유향, 기온, 수온,풍속,유속,기압,습도)만 선택하여 사용\n",
    "\n",
    "- 기상청 데이터: https://marineweather.nmpnt.go.kr/statistic/searchStatisticList.do\n",
    "- 1차: 다양한 값이 측정이 되어 있는 부산청 => 신항유도등부표(랜비)의 등대 기상청 데이터를 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     지방청           표지                일시  풍향(˚)  유향(˚)  기온(℃)  수온(℃)  풍속(m/s)   \n",
      "0    부산청  신항유도등부표(랜비)  2023-05-11 23:50    100     80   15.9   16.5    2.570  \\\n",
      "1    부산청  신항유도등부표(랜비)  2023-05-11 23:40    114     78   16.7   16.3    1.540   \n",
      "2    부산청  신항유도등부표(랜비)  2023-05-11 23:30    114     94   15.8   16.4    1.540   \n",
      "3    부산청  신항유도등부표(랜비)  2023-05-11 23:20    150     92   16.0   16.6    0.514   \n",
      "4    부산청  신항유도등부표(랜비)  2023-05-11 23:10    142     74   17.0   16.6    1.030   \n",
      "..   ...          ...               ...    ...    ...    ...    ...      ...   \n",
      "139  부산청  신항유도등부표(랜비)  2023-05-11 00:40    150    125   14.6   16.6    0.000   \n",
      "140  부산청  신항유도등부표(랜비)  2023-05-11 00:30    142    146   14.5   16.8    0.000   \n",
      "141  부산청  신항유도등부표(랜비)  2023-05-11 00:20    149    100   15.5   16.9    0.514   \n",
      "142  부산청  신항유도등부표(랜비)  2023-05-11 00:10    157    103   16.1   17.0    0.000   \n",
      "143  부산청  신항유도등부표(랜비)  2023-05-11 00:00    184     68   15.1   16.9    0.514   \n",
      "\n",
      "     유속(kn)  기압(hPa)  습도(%)  \n",
      "0       0.8     1017     46  \n",
      "1       1.1     1017     48  \n",
      "2       0.6     1017     48  \n",
      "3       0.8     1017     51  \n",
      "4       0.6     1017     48  \n",
      "..      ...      ...    ...  \n",
      "139     0.5     1015     89  \n",
      "140     0.4     1015     89  \n",
      "141     0.4     1015     90  \n",
      "142     0.5     1015     86  \n",
      "143     0.6     1015     84  \n",
      "\n",
      "[144 rows x 11 columns]\n",
      "(144, 11)\n",
      "   지방청           표지                일시  풍향(˚)  유향(˚)  기온(℃)  수온(℃)  풍속(m/s)   \n",
      "0  부산청  신항유도등부표(랜비)  2023-05-11 23:50    100     80   15.9   16.5    2.570  \\\n",
      "1  부산청  신항유도등부표(랜비)  2023-05-11 23:40    114     78   16.7   16.3    1.540   \n",
      "2  부산청  신항유도등부표(랜비)  2023-05-11 23:30    114     94   15.8   16.4    1.540   \n",
      "3  부산청  신항유도등부표(랜비)  2023-05-11 23:20    150     92   16.0   16.6    0.514   \n",
      "4  부산청  신항유도등부표(랜비)  2023-05-11 23:10    142     74   17.0   16.6    1.030   \n",
      "\n",
      "   유속(kn)  기압(hPa)  습도(%)  \n",
      "0     0.8     1017     46  \n",
      "1     1.1     1017     48  \n",
      "2     0.6     1017     48  \n",
      "3     0.8     1017     51  \n",
      "4     0.6     1017     48  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "excel_file = 'D:/장우영/LOCALSEARCH\\DA\\DA\\data/05_11 기상청 데이터.xls'\n",
    "\n",
    "weather_data = pd.read_excel(excel_file)\n",
    "\n",
    "\n",
    "# 데이터 확인 \n",
    "print(weather_data)\n",
    "print(weather_data.shape) # 144,11\n",
    "print(weather_data.head(5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/%EA%B8%B0%EC%83%81%EC%B2%AD%20%EB%8D%B0%EC%9D%B4%ED%84%B0%20%EC%9D%B4%EB%AF%B8%EC%A7%80.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지방청        0\n",
      "표지         0\n",
      "일시         0\n",
      "풍향(˚)      0\n",
      "유향(˚)      0\n",
      "기온(℃)      0\n",
      "수온(℃)      0\n",
      "풍속(m/s)    0\n",
      "유속(kn)     0\n",
      "기압(hPa)    0\n",
      "습도(%)      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NaN (결측치)값 확인\n",
    "print(weather_data.isna().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) AIS 데이터와 기상청에서 제공하는 해양 기상 데이터를 이용하여 입력 데이터와 출력 데이터를 구성\n",
    "-          독립변수 :  풍향,유향,기온,풍속,유속,기압,습도(기상청데이터)\n",
    "\t\t\t  \t\t  mmsi(AIS데이터),선박의 위치(위도, 경도), cog(이동하는 방향각), sog(수신기가 이동하는 속도)\n",
    "\t\t\t\t\t  \n",
    "-          종속변수 : 선박의 위치(위도, 경도), cog(이동하는 방향각), sog(수신기가 이동하는 속도)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) 해당 데이터 모델을 시간을 기준으로 데이터를 병합\n",
    "- AIS 데이터셋과 기상청 데이터셋을 모두 일시(시간)이 있어서 초단위인 AIS 데이터 시간을 기준(초 단위)으로 자바를 이용하여 데이터를 병합 \n",
    "- AIS 데이터셋이 기준: 데이터 손실을 막기 위해\n",
    "\n",
    "- 시간에 따라 이러한 데이터 포인트를 시퀀스 형태로 모아 모델의 입력으로 사용하기\n",
    "\n",
    "- AData 객체의 cust_time과 FData 객체의 ilsi 필드 사이에서 가장 가까운 시간을 가지고 있는 FData 객체가 병합됩니다.\n",
    "- AIS Adata cust_time인 2023-05-11 10:19:59와 Fdata 일시 ilsi인 2023-05-11 10:10:00 사이에서 가장 가까운 시간을 가지는 FData 객체가 병합\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "package com.gc;\n",
    "\n",
    "import java.io.BufferedReader;\n",
    "import java.io.BufferedWriter;\n",
    "import java.io.FileOutputStream;\n",
    "import java.io.FileReader;\n",
    "import java.io.IOException;\n",
    "import java.io.OutputStreamWriter;\n",
    "import java.text.SimpleDateFormat;\n",
    "import java.time.LocalDateTime;\n",
    "import java.time.format.DateTimeFormatter;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Date;\n",
    "\n",
    "// 지방청\t표지\t일시\t풍향(˚)\t유향(˚)\t기온(℃)\t수온(℃)\t풍속(m/s)\t유속(kn)\t기압(hPa)\t습도(%)\n",
    "\n",
    "public class DataMergeMainBackup {\n",
    "\t// ==============================================================================================\n",
    "\n",
    "\t// 2023-05-11 10:10:58의 데이터 형식을 올바르게 출력하기 위한 코드 => 날짜 및 시간의 문자열 표현을 개체로 변환하는\n",
    "\t// Util 유틸리티 메서드\n",
    "\tclass Util {\n",
    "\t\tpublic static LocalDateTime stringtoDate(String str, String pattern) {\n",
    "\t\t\tDateTimeFormatter formatter = DateTimeFormatter.ofPattern(pattern);\n",
    "\t\t\treturn LocalDateTime.parse(str, formatter);\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\t// 기상청 데이터\n",
    "\tclass FData {\n",
    "\t\tString govName; // 지방청\n",
    "\t\tString pyogi; // 표지\n",
    "\t\tLocalDateTime ilsi; // 날짜 및 시간(일시)\n",
    "\t\tint windDir; // 풍향\n",
    "\t\tint waveDir; // 유향\n",
    "\t\tdouble airTemp; // 기온\n",
    "\t\tdouble waterTemp; // 수온\n",
    "\t\tdouble windSpeed; // 풍속\n",
    "\t\tdouble waterSpeed; // 유속\n",
    "\t\tint hPa; // 기압\n",
    "\t\tint humidity; // 습도\n",
    "\t\tString source;\n",
    "\n",
    "\t\tpublic FData(String str) {\n",
    "\t\t\tsource = str;\n",
    "\t\t\t// 문자열을 구문 분석\n",
    "\t\t\tString[] array = str.split(\",\");\n",
    "\t\t\tgovName = array[0];\n",
    "\t\t\tpyogi = array[1];\n",
    "\t\t\tilsi = Util.stringtoDate(array[2], \"yyyy-MM-dd HH:mm\");\n",
    "\t\t\t// windDir의 형식이 int이기 때문에 =>\n",
    "\t\t\tif (array[3].length() == 0) // 만약 windDir의 값이 없으면 => 0\n",
    "\t\t\t\twindDir = 0; // 바람의 방향이 없음\n",
    "\t\t\telse // 있다면 값을 넣어줌\n",
    "\t\t\t\twindDir = Integer.parseInt(array[3]);\n",
    "\t\t\tif (array[4].length() == 0)\n",
    "\t\t\t\twaveDir = 0;\n",
    "\t\t\telse\n",
    "\t\t\t\twaveDir = Integer.parseInt(array[4]);\n",
    "\t\t\tif (array[5].length() == 0)\n",
    "\t\t\t\tairTemp = 0.0;\n",
    "\t\t\telse\n",
    "\t\t\t\tairTemp = Double.parseDouble(array[5]);\n",
    "\t\t\tif (array[6].length() == 0)\n",
    "\t\t\t\twaterTemp = 0.0;\n",
    "\t\t\telse\n",
    "\t\t\t\twaterTemp = Double.parseDouble(array[6]);\n",
    "\t\t\tif (array[7].length() == 0)\n",
    "\t\t\t\twindSpeed = 0.0;\n",
    "\t\t\telse\n",
    "\t\t\t\twindSpeed = Double.parseDouble(array[7]);\n",
    "\t\t\tif (array[8].length() == 0)\n",
    "\t\t\t\twaterSpeed = 0.0;\n",
    "\t\t\telse\n",
    "\t\t\t\twaterSpeed = Double.parseDouble(array[8]);\n",
    "\t\t\tif (array[9].length() == 0)\n",
    "\t\t\t\thPa = 0;\n",
    "\t\t\telse\n",
    "\t\t\t\thPa = Integer.parseInt(array[9]);\n",
    "\t\t\tif (array[10].length() == 0)\n",
    "\t\t\t\thumidity = 0;\n",
    "\t\t\telse\n",
    "\t\t\t\thumidity = Integer.parseInt(array[10]);\n",
    "\t\t}\n",
    "\n",
    "\t\t@Override\n",
    "\t\tpublic String toString() {\n",
    "\t\t\treturn \"FData [govName=\" + govName + \", pyogi=\" + pyogi + \", ilsi=\" + ilsi + \", windDir=\" + windDir\n",
    "\t\t\t\t\t+ \", waveDir=\" + waveDir + \", airTemp=\" + airTemp + \", waterTemp=\" + waterTemp + \", windSpeed=\"\n",
    "\t\t\t\t\t+ windSpeed + \", waterSpeed=\" + waterSpeed + \", hPa=\" + hPa + \", humidity=\" + humidity + \"]\";\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "//\t \tmmsi\tship_name\tship_type\tgeom\tcog\t\tsog\t\tinsert_time\n",
    "\n",
    "\t// GC AIS데이터\n",
    "\tclass AData {\n",
    "\t\tString mmsi; // mmis\n",
    "\t\tString ship_name; // 선박 이름\n",
    "\t\tint ship_type; // 선박 유형\n",
    "\t\tString geom; // 경도 위도\n",
    "\t\tdouble cog; // 지상 코스\n",
    "\t\tdouble sog; // 지상 속도\n",
    "\t\tLocalDateTime insert_time; // 데이터가 들어온 시간\n",
    "\t\tLocalDateTime cust_time; // 데이터가 들어온 시간에서 초를 뺸 시간\n",
    "\t\tFData fdata;\n",
    "\t\tString source;\n",
    "\n",
    "\t\tpublic AData(String str) {\n",
    "\t\t\t// 문자열을 구문 분석\n",
    "\t\t\tsource = str;\n",
    "\t\t\tString[] array = str.split(\",\");\n",
    "\t\t\tmmsi = array[0];\n",
    "\t\t\tship_name = array[1];\n",
    "\t\t\tif (array[2].length() == 0)\n",
    "\t\t\t\tship_type = 0;\n",
    "\t\t\telse\n",
    "\t\t\t\tship_type = Integer.parseInt(array[2]);\n",
    "\t\t\tgeom = array[3];\n",
    "\t\t\tif (array[4].length() == 0)\n",
    "\t\t\t\tcog = 0;\n",
    "\t\t\telse\n",
    "\t\t\t\tcog = Double.parseDouble(array[4]);\n",
    "\t\t\tif (array[5].length() == 0)\n",
    "\t\t\t\tsog = 0;\n",
    "\t\t\telse\n",
    "\t\t\t\tsog = Double.parseDouble(array[5]);\n",
    "\t\t\tinsert_time = Util.stringtoDate(array[6], \"yyyy-MM-dd HH:mm:ss\");\n",
    "\n",
    "\t\t\t// 삽입 시간 값의 일부를 추출 => yyyy-MM-dd HH:mm\n",
    "\t\t\t// 초 자리 표시자로 \"0\"을 추가하여 삽입 시간 값을 수정\n",
    "\t\t\tString t = array[6].substring(0, array[6].length() - 4) + \"0\";\n",
    "\t\t\tcust_time = Util.stringtoDate(t, \"yyyy-MM-dd HH:mm\");\n",
    "\n",
    "\t\t}\n",
    "\n",
    "\t\t@Override\n",
    "\t\tpublic String toString() {\n",
    "\t\t\treturn \"AData [mmsi=\" + mmsi + \", ship_name=\" + ship_name + \", ship_type=\" + ship_type + \", geom=\" + geom\n",
    "\t\t\t\t\t+ \", cog=\" + cog + \", sog=\" + sog + \", insert_time=\" + insert_time + \", cust_time=\" + cust_time\n",
    "\t\t\t\t\t+ \"]\";\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\t// 기상청 데이터\n",
    "\tArrayList<FData> FDlist = new ArrayList<>();\n",
    "\n",
    "\t// 일기예보 데이터 읽기 및 저장\n",
    "\tpublic void readForcastData(String fname) throws Exception {\n",
    "\t\tSystem.out.println(\"readForcastData: \" + fname);\n",
    "\t\ttry (BufferedReader br = new BufferedReader(new FileReader(fname));) {\n",
    "\t\t\tString str;\n",
    "\t\t\tbr.readLine();\n",
    "\t\t\twhile ((str = br.readLine()) != null) {\n",
    "\t\t\t\t// System.out.println(str);\n",
    "\t\t\t\tFData fd = new FData(str);\n",
    "\t\t\t\tFDlist.add(fd);\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tpublic void printForcastData() {\n",
    "\t\t// System.out.println(\"printForcastData\");\n",
    "\t\tfor (FData fd : FDlist) {\n",
    "\t\t\tSystem.out.println(fd);\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// ==============================================================================================\n",
    "\n",
    "\t// Ais 데이터\n",
    "\tArrayList<AData> ASlist = new ArrayList<>();\n",
    "\n",
    "\t// Ais 데이터 읽기 및 저장\n",
    "\tpublic void readAISData(String fname) throws Exception {\n",
    "\t\tSystem.out.println(\"readForcastData: \" + fname);\n",
    "\t\ttry (BufferedReader br = new BufferedReader(new FileReader(fname));) {\n",
    "\t\t\tString str;\n",
    "\t\t\tbr.readLine();\n",
    "\t\t\twhile ((str = br.readLine()) != null) {\n",
    "\t\t\t\t// System.out.println(str);\n",
    "\t\t\t\tAData ad = new AData(str);\n",
    "\t\t\t\tASlist.add(ad);\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tpublic void printAISData() {\n",
    "\t\t// System.out.println(\"printForcastData\");\n",
    "\t\tfor (AData ad : ASlist) {\n",
    "\t\t\tSystem.out.println(ad);\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tpublic void printAISTimeDate() {\n",
    "\t\tfor (AData ad : ASlist) {\n",
    "\t\t\tSystem.out.println(\"insert_time=\" + ad.insert_time + \", cust_time=\" + ad.cust_time);\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "//  AISDATA에 FDATA를 mapping하는 코드\n",
    "\tpublic void mappingData() {\n",
    "\t\tfor (AData ad : ASlist) {\n",
    "\t\t\tfor (FData fd : FDlist) {\n",
    "\t\t\t\tif (ad.cust_time.equals(fd.ilsi)) {\n",
    "\t\t\t\t\tad.fdata = fd;\n",
    "\t\t\t\t}\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tpublic void printMappingData() {\n",
    "\n",
    "\t\tfor (int i = 0; i < 100; i++) {\n",
    "\t\t\tAData ad = ASlist.get(i);\n",
    "\t\t\tSystem.out.println(\"mmsi=\" + ad.mmsi + \", cust_time=\" + ad.cust_time + \", windDir=\" + ad.fdata.windDir\n",
    "\t\t\t\t\t+ \", waveDir=\" + ad.fdata.waveDir);\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\tpublic void writeData(String fname) throws IOException {\n",
    "\t\t// try (BufferedWriter bw = new BufferedWriter(new FileWriter(fname));) {\n",
    "\t\ttry (BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(new FileOutputStream(fname), \"KSC5601\"));) {\n",
    "\n",
    "\t\t\tfor (AData ad : ASlist) {\n",
    "\t\t\t\tbw.write(String.format(\"%s,%s\\n\", ad.source, ad.fdata.source));\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\tSystem.out.println(fname);\n",
    "\t}\n",
    "\n",
    "\t// \"D:\\장우영\\LOCALSEARCH\\DA\\DA\\data\" \"05_11 기상청 데이터.csv\" \"Ais_Test.csv\"\n",
    "\tpublic static void main(String[] args) throws Exception {\n",
    "\t\tDataMergeMainBackup dmn = new DataMergeMainBackup();\n",
    "\t\tSystem.out.println(args[0]);\n",
    "\t\tSystem.out.println(args[1]);\n",
    "\t\tSystem.out.println(args[2]);\n",
    "\n",
    "\t\t// 일기 예보 데이터의 파일\n",
    "\t\tdmn.readForcastData(args[0] + \"\\\\\" + args[1]);\n",
    "\t\t// dmn.printForcastData();\n",
    "\n",
    "\t\t// AIS 데이터의 파일\n",
    "\t\tdmn.readAISData(args[0] + \"\\\\\" + args[2]);\n",
    "\t\t// dmn.printAISData();\n",
    "\t\t// dmn.printAISTimeDate();\n",
    "\n",
    "\t\t// 그런 다음 예보 및 AIS 데이터를 읽고 데이터를 매핑하고 매핑된 데이터를 \"FAmerge.csv\"라는 파일에 씁니다.\n",
    "\t\tdmn.mappingData();\n",
    "\t\t// dmn.printMappingData();\n",
    "\t\tSimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMdd_HHmmss\");\n",
    "\t\tString fname = args[0] + \"\\\\FAmerge_\" + sdf.format(new Date()) + \".csv\";\n",
    "\t\t// dmn.writeData(\"fname\");\n",
    "\t\tdmn.writeData(fname);\n",
    "\t\t// System.out.println(fname);\n",
    "\t\tSystem.out.println(\"End\");\n",
    "\t}\n",
    "\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 해당 병합 코드를 이용해서 시간을 기준으로 병합한 csv 파일 만들기\n",
    "-  CSV 파일에서 예보 데이터와 AIS 데이터를 읽고 공통 시간 값을 기반으로 데이터를 매핑하고 매핑된 데이터를 새 CSV 파일에 씁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mmsi      ship_name  ship_type   \n",
      "0  440051540           D-01          0  \\\n",
      "1  440300780            NaN          0   \n",
      "2  440208550            NaN          0   \n",
      "3  440275000  GBK EXPRESS 1         40   \n",
      "4  440414850   NO1 GEO SUNG         80   \n",
      "\n",
      "                                                geom    cog  sog   \n",
      "0  0101000020110F00000000002039676B41000000002DCF...  329.2  5.7  \\\n",
      "1  0101000020110F0000000000C0D2666B410000008079E5...  329.8  0.0   \n",
      "2  0101000020110F00000000002062656B4100000080F0DD...  139.3  0.0   \n",
      "3  0101000020110F000000000040A1666B41000000800AE4...  175.8  0.0   \n",
      "4  0101000020110F00000000004097666B410000008067E5...    0.0  0.0   \n",
      "\n",
      "           insert_time  지방청           표지                   일시   풍향   유향    기온   \n",
      "0  2023-05-11 10:10:58  부산청  신항유도등부표(랜비)  2023-05-11 10:10:00  196  246  16.4  \\\n",
      "1  2023-05-11 10:10:58  부산청  신항유도등부표(랜비)  2023-05-11 10:10:00  196  246  16.4   \n",
      "2  2023-05-11 10:10:58  부산청  신항유도등부표(랜비)  2023-05-11 10:10:00  196  246  16.4   \n",
      "3  2023-05-11 10:10:58  부산청  신항유도등부표(랜비)  2023-05-11 10:10:00  196  246  16.4   \n",
      "4  2023-05-11 10:10:58  부산청  신항유도등부표(랜비)  2023-05-11 10:10:00  196  246  16.4   \n",
      "\n",
      "     수온    풍속   유속    기압  습도  \n",
      "0  17.0  9.77  0.3  1017  82  \n",
      "1  17.0  9.77  0.3  1017  82  \n",
      "2  17.0  9.77  0.3  1017  82  \n",
      "3  17.0  9.77  0.3  1017  82  \n",
      "4  17.0  9.77  0.3  1017  82  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/DA/DA/data/FAmerge_20230602_101301.csv', encoding='ANSI')\n",
    "#print(data)\n",
    "print(data.head(5))\n",
    "\n",
    "# 2023.05.11 10시 10분 ~ 2023.05.11 11시 20분 (1시간 10분 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/101301merge_data.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2023-05-11 10:10:58\n",
      "1        2023-05-11 10:10:58\n",
      "2        2023-05-11 10:10:58\n",
      "3        2023-05-11 10:10:58\n",
      "4        2023-05-11 10:10:58\n",
      "                ...         \n",
      "52732    2023-05-11 11:19:59\n",
      "52733    2023-05-11 11:19:59\n",
      "52734    2023-05-11 11:19:59\n",
      "52735    2023-05-11 11:19:59\n",
      "52736    2023-05-11 11:19:59\n",
      "Name: 일시, Length: 52737, dtype: object\n",
      "0        2023-05-11 10:10:58\n",
      "1        2023-05-11 10:10:58\n",
      "2        2023-05-11 10:10:58\n",
      "3        2023-05-11 10:10:58\n",
      "4        2023-05-11 10:10:58\n",
      "                ...         \n",
      "52732    2023-05-11 11:19:59\n",
      "52733    2023-05-11 11:19:59\n",
      "52734    2023-05-11 11:19:59\n",
      "52735    2023-05-11 11:19:59\n",
      "52736    2023-05-11 11:19:59\n",
      "Name: insert_time, Length: 52737, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/DA/DA/data/FAmerge_20230531_103345.csv', encoding='ANSI')\n",
    "\n",
    "# B열 값을 A열의 값으로 변환\n",
    "data['일시'] = data['insert_time']\n",
    "\n",
    "# 변환된 데이터를 새로운 CSV 파일로 저장\n",
    "data.to_csv('D:/장우영/LOCALSEARCH/DA/DA/data/변환된_파일명.csv',  encoding='ANSI')\n",
    "print(data.일시)\n",
    "print(data.insert_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        2023-05-11 10:10:58\n",
      "1        2023-05-11 10:10:58\n",
      "2        2023-05-11 10:10:58\n",
      "3        2023-05-11 10:10:58\n",
      "4        2023-05-11 10:10:58\n",
      "                ...         \n",
      "52732    2023-05-11 11:19:59\n",
      "52733    2023-05-11 11:19:59\n",
      "52734    2023-05-11 11:19:59\n",
      "52735    2023-05-11 11:19:59\n",
      "52736    2023-05-11 11:19:59\n",
      "Name: insert_time, Length: 52737, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load data from CSV file\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/DA/DA/data/FAmerge_20230531_103345.csv', encoding='ANSI')\n",
    "print(data.insert_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52737, 18)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "\n",
    "# (52737, 18)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 병합 데이터 분석,전처리 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmsi              0\n",
      "ship_name      7875\n",
      "ship_type         0\n",
      "geom              0\n",
      "cog               0\n",
      "sog               0\n",
      "insert_time       0\n",
      "지방청               0\n",
      "표지                0\n",
      "일시                0\n",
      "풍향                0\n",
      "유향                0\n",
      "기온                0\n",
      "수온                0\n",
      "풍속                0\n",
      "유속                0\n",
      "기압                0\n",
      "습도                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NaN 값 확인\n",
    "print(data.isna().sum())\n",
    "# shipname의 값  7875개 null"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AIS 데이터의 geom(좌표값) => 위도,경도 값으로 출력\n",
    "- geom  = WKB 문자열은 이진 형식의 기하학적 개체(기하학적 문자열)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.11061897120135 129.0690596733144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyproj\\crs\\crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\SW\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyproj\\crs\\crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "C:\\Users\\SW\\AppData\\Local\\Temp\\ipykernel_5360\\11607251.py:24: FutureWarning: This function is deprecated. See: https://pyproj4.github.io/pyproj/stable/gotchas.html#upgrading-to-pyproj-2-from-pyproj-1\n",
      "  transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n"
     ]
    }
   ],
   "source": [
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "\n",
    "# 주어진 WKB 문자열\n",
    "wkb_string = '0101000020110F0000000000C093676B4100000000F6E14F41'\n",
    "\n",
    "# 1단계: 16진수 문자열을 2진수로 디코딩\n",
    "binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "# 2단계: 이진 문자열 구문 분석\n",
    "geometry = wkb.loads(binary_string)\n",
    "\n",
    "# 3단계: 좌표를 위도와 경도로 변환\n",
    "if geometry and hasattr(geometry, 'wkt'):\n",
    "    # WKT(Well-Known Text) 형식으로 변환\n",
    "    wkt = geometry.wkt\n",
    "\n",
    "    # 좌표계 변환 정의 3857 => 4326\n",
    "    crs_from = pyproj.Proj(init='epsg:3857')\n",
    "    crs_to = pyproj.Proj(init='epsg:4326')\n",
    "\n",
    "    # 좌표 변환 수행\n",
    "    transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "\n",
    "    # 위도와 경도 추출\n",
    "    latitude, longitude = transformed[1], transformed[0]\n",
    "\n",
    "    # latitude and longitude 값 출력\n",
    "    print(latitude, longitude)\n",
    "else:\n",
    "    print('\"잘못된 기하학 데이터')\n",
    "\n",
    " # 35.123838041911526 129.0551896853276\n",
    " # 35.11222830013471 129.0684757683797"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 셈플 데이터 100개 geom => 위도,경도 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     latitude   longitude\n",
      "0   35.039909  129.062547\n",
      "1   35.123838  129.055190\n",
      "2   35.095487  129.028698\n",
      "3   35.118445  129.051632\n",
      "4   35.123574  129.050914\n",
      "..        ...         ...\n",
      "95  35.083028  128.996242\n",
      "96  34.712431  129.067003\n",
      "97  35.078323  129.107256\n",
      "98  35.119371  129.050914\n",
      "99  35.088622  129.026821\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "        latitude   longitude    cog  sog\n",
      "0      35.039909  129.062547  329.2  5.7\n",
      "1      35.123838  129.055190  329.8  0.0\n",
      "2      35.095487  129.028698  139.3  0.0\n",
      "3      35.118445  129.051632  175.8  0.0\n",
      "4      35.123574  129.050914    0.0  0.0\n",
      "...          ...         ...    ...  ...\n",
      "47994        NaN         NaN    NaN  NaN\n",
      "47995        NaN         NaN    NaN  NaN\n",
      "47996        NaN         NaN    NaN  NaN\n",
      "47997        NaN         NaN    NaN  NaN\n",
      "47998        NaN         NaN    NaN  NaN\n",
      "\n",
      "[47999 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "\n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱\n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "\n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "#  CSV 파일에서 데이터 로드\n",
    "data = pd.read_csv('D:\\\\장우영\\\\LOCALSEARCH\\\\DA\\\\DA\\\\data\\\\FAmerge_20230523_161834_simple.csv', encoding='ANSI',low_memory=False)\n",
    "\n",
    "# # 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "print(data[['latitude', 'longitude']].head(100))\n",
    "\n",
    "# \"insert_time\"을 숫자로 변환\n",
    "data['insert_time'] = pd.to_datetime(data['insert_time']).astype('int64') // 10**9\n",
    "\n",
    "# 특성과 타겟 변수 선택\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"insert_time\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "y = data[[\"latitude\", \"longitude\", \"cog\", \"sog\"]]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터모델 분석\n",
    " ### 1) 선형 회귀 모델 \n",
    "\n",
    " - 전반적으로 이 코드는 데이터 전처리, 기능 엔지니어링 및 선형 회귀 모델링을 수행하여 제공된 기능을 기반으로 위도, 경도, 지상 코스(cog) 및 지상 속도(sog)를 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mmsi  ship_type   latitude   longitude    cog  sog  year  month   \n",
      "0      440051540          0  35.039909  129.062547  329.2  5.7  2023      5  \\\n",
      "1      440300780          0  35.123838  129.055190  329.8  0.0  2023      5   \n",
      "2      440208550          0  35.095487  129.028698  139.3  0.0  2023      5   \n",
      "3      440275000         40  35.118445  129.051632  175.8  0.0  2023      5   \n",
      "4      440414850         80  35.123574  129.050914    0.0  0.0  2023      5   \n",
      "...          ...        ...        ...         ...    ...  ...   ...    ...   \n",
      "52732  440314810         80  35.105600  129.090395  347.5  0.1  2023      5   \n",
      "52733  440001860         80  35.124014  129.051992    0.0  0.0  2023      5   \n",
      "52734  440117010         80  35.032179  129.042892   53.8  0.1  2023      5   \n",
      "52735  440101390          0  35.093532  129.025455  254.6  0.0  2023      5   \n",
      "52736  440233000         60  35.115888  129.049153  360.0  0.0  2023      5   \n",
      "\n",
      "       day  hour  minute  second   풍향   유향    기온    수온    풍속   유속    기압  습도  \n",
      "0       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "1       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "2       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "3       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "4       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "...    ...   ...     ...     ...  ...  ...   ...   ...   ...  ...   ...  ..  \n",
      "52732   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52733   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52734   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52735   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52736   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "\n",
      "[52737 rows x 20 columns]\n",
      "Mean Squared Error: 2.5777660104738737e-23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "\n",
    "# 이 함수는 WKB 문자열을 입력으로 사용하고 다양한 단계를 수행하여 위도 및 경도 좌표로 변환  \n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱\n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "\n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "# 2023.05.11 10시 10분 ~ 2023.05.11 11시 20분 (1시간 10분 데이터)\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/DA/DA/data/FAmerge_20230531_103345.csv', encoding='ANSI')\n",
    "\n",
    "# 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "#print(data[['latitude', 'longitude']].head(100))\n",
    "\n",
    "\n",
    "# 'insert_time'을 숫자 기능으로 변환:\n",
    "#  datetime접근자를 사용 pd.to_datetime하고 접근자를 사용 하여 'insert_time' 열에서 다양한 시간적 특징(년, 월, 일, 시, 분, 초)을 추출\n",
    "# data['insert_time'] = pd.to_datetime(data['insert_time']).astype('int64') // 10**9\n",
    "data['year'] = pd.to_datetime(data['insert_time']).dt.year\n",
    "data['month'] = pd.to_datetime(data['insert_time']).dt.month\n",
    "data['day'] = pd.to_datetime(data['insert_time']).dt.day\n",
    "data['hour'] = pd.to_datetime(data['insert_time']).dt.hour\n",
    "data['minute'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "data['second'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "\n",
    "#print(data['insert_time'])\n",
    "\n",
    "#특성과 타겟 변수 선택 # cog(방향), sog(속도)\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "y = data[[\"latitude\", \"longitude\",\"cog\", \"sog\"]]\n",
    "print(X)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 선형 회귀 모델 생성 및 훈련\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 목표 값 예측\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 평균 오차값 예측\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대상 값 예측: 이 코드는 훈련된 모델을 사용하여 테스트 세트의 대상 값(위도, 경도, COG, SOG)을 예측합니다.\n",
    "\n",
    "- 평균 제곱 오차(MSE) 계산:mean_squared_error 이 코드는 sklearn의 함수를 사용하여 예측 목표 값과 실제 목표 값 사이의 평균 제곱 오차를 계산합니다 .\n",
    "\n",
    "- Mean Squared Error: 2.5777660104738737e-23 == 매우 낮은 오차를 달성\n",
    "\n",
    "- 선형모델이므로 단순 계산식 => 과적합 의심"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flask를 사용해서 \"/predict\" api를 작동하게 만들기\n",
    "- 확인은 postman사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('linear_regression_linearmodel_.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델을 불러오기 위해 pickle 파일을 엽니다.\n",
    "model = pickle.load(open('linear_regression_linearmodel_.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# 훈련된 선형 회귀 모델 불러오기\n",
    "model = pickle.load(open('D:/장우영/LOCALSEARCH/DA/DA/notebooks/linear_regression_linearmodel_.pkl', 'rb'))\n",
    "\n",
    "# 예측 끝점 정의    \n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # 들어오는 요청에서 데이터 가져오기\n",
    "    data = request.json\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    mmsi = data[\"mmsi\"]\n",
    "    ship_type = data[\"ship_type\"]\n",
    "    latitude = data[\"latitude\"]\n",
    "    longitude = data[\"longitude\"]\n",
    "    cog = data[\"cog\"]\n",
    "    sog = data[\"sog\"]\n",
    "    insert_time = pd.Timestamp(data[\"insert_time\"]).strftime('%Y-%m-%d %H:%M:%S')  # Convert to Unix timestamp\n",
    "    wind_direction = data[\"풍향\"]\n",
    "    direction = data[\"유향\"]\n",
    "    temperature = data[\"기온\"]\n",
    "    water_temperature = data[\"수온\"]\n",
    "    wind_speed = data[\"풍속\"]\n",
    "    flow_speed = data[\"유속\"]\n",
    "    air_pressure = data[\"기압\"]\n",
    "    humidity = data[\"습도\"]\n",
    "    \n",
    "    # 입력 데이터로 DataFrame 생성  \n",
    "    input_data = pd.DataFrame({\n",
    "            \"mmsi\": [mmsi],\n",
    "            \"ship_type\": [ship_type],\n",
    "            \"latitude\": [latitude],\n",
    "            \"longitude\": [longitude],\n",
    "            \"cog\": [cog],\n",
    "            \"sog\": [sog],\n",
    "            # , unit='s'\n",
    "            \"year\": [pd.to_datetime(insert_time).year],\n",
    "            \"month\": [pd.to_datetime(insert_time).month],\n",
    "            \"day\": [pd.to_datetime(insert_time).day],\n",
    "            \"hour\": [pd.to_datetime(insert_time).hour],\n",
    "            \"minute\": [pd.to_datetime(insert_time).minute],\n",
    "            \"second\": [pd.to_datetime(insert_time).second],\n",
    "            \"풍향\": [wind_direction],\n",
    "            \"유향\": [direction],\n",
    "            \"기온\": [temperature],\n",
    "            \"수온\": [water_temperature],\n",
    "            \"풍속\": [wind_speed],\n",
    "            \"유속\": [flow_speed],\n",
    "            \"기압\": [air_pressure],\n",
    "            \"습도\": [humidity]\n",
    "        })\n",
    "    \n",
    "    # 훈련된 모델을 사용하여 예측하기\n",
    "    prediction = model.predict(input_data)\n",
    "    \n",
    "    # 응답 JSON 생성\n",
    "    response = {\n",
    "        \"latitude\": prediction[0][0],\n",
    "        \"longitude\": prediction[0][1],\n",
    "        \"predicted_cog\": prediction[0][2],\n",
    "        \"predicted_sog\": prediction[0][3]\n",
    "    }\n",
    "    \n",
    "    # 응답을 JSON으로 반환\n",
    "    return jsonify(response)\n",
    "\n",
    "# 플라스크 애플리케이션 실행\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/%EC%84%A0%ED%98%95.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2) LSTM 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 모델 만들기!  아직 수정 중!!! \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pyproj import Transformer\n",
    "\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "\n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱 \n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "\n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "# CSV 파일에서 데이터 로드\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/Ship_DA/DA/data/FAmerge_20230607_1147142.csv', encoding='ANSI')\n",
    "\n",
    "# 특정 칼럼의 조건에 따라 데이터 필터링\n",
    "filtered_data = data[data['sog'] > 3]  # 특정 칼럼과 조건을 적절히 수정해야 합니다\n",
    "\n",
    "data= filtered_data\n",
    "\n",
    "# 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "#print(data[['latitude', 'longitude']])\n",
    "\n",
    "# \"insert_time\"을 숫자로 변환\n",
    "data['year'] = pd.to_datetime(data['insert_time']).dt.year\n",
    "data['month'] = pd.to_datetime(data['insert_time']).dt.month\n",
    "data['day'] = pd.to_datetime(data['insert_time']).dt.day\n",
    "data['hour'] = pd.to_datetime(data['insert_time']).dt.hour\n",
    "data['minute'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "data['second'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "\n",
    "\n",
    "# 특성과 타겟 변수 선택\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "X['minute'] = pd.to_datetime(data['insert_time']).dt.minute + 1\n",
    "y = data[[\"latitude\", \"longitude\",\"cog\", \"sog\"]]\n",
    "\n",
    "print(X)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MinMaxScaler를 사용하여 입력 특성 스케일 조정\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LSTM에 맞게 입력 데이터 형태 변환\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "\n",
    "# LSTM 모델 생성\n",
    "model_LSTRM = Sequential()\n",
    "model_LSTRM.add(LSTM(64, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model_LSTRM.add(Dense(4))  # 출력층, 4개의 뉴런 (latitude, longitude, sog, cog)\n",
    "\n",
    "# 모델 컴파일\n",
    "model_LSTRM.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 조기 종료를 위한 EarlyStopping 정의\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# LSTM 모델 훈련\n",
    "history = model_LSTRM.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# LSTM 모델을 사용하여 예측 수행\n",
    "y_pred = model_LSTRM.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to a list\n",
    "y_pred_list = y_pred.tolist()\n",
    "\n",
    "# 평균 제곱 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# y_test(실제 값)와 y_pred(예측 값) 사이의 R-제곱 값을 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "\n",
    "# Create the response JSON\n",
    "response = {\n",
    "    \"latitude\": y_pred_list[0][0],\n",
    "    \"longitude\": y_pred_list[0][1],\n",
    "    \"predicted_cog\": y_pred_list[0][2],\n",
    "    \"predicted_sog\": y_pred_list[0][3]\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/LSTM%EA%B2%B0%EA%B3%BC%EA%B0%92.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드는 LSTM(Long Short-Term Memory) 모델을 사용하여 데이터를 훈련하고 예측 \n",
    "\n",
    "# 필요한 라이브러리를 import합니다.\n",
    "# 좌표 변환 함수를 정의합니다.\n",
    "# CSV 파일에서 데이터를 로드합니다.\n",
    "# 좌표 변환을 적용하고 \"insert_time\"을 숫자로 변환합니다.\n",
    "# 특성과 타겟 변수를 선택합니다.\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할합니다.\n",
    "# 입력 특성을 스케일 조정합니다.\n",
    "# LSTM에 입력하기 위해 데이터의 형태를 변환합니다.\n",
    "# LSTM 모델을 생성합니다.\n",
    "# 모델을 컴파일합니다.\n",
    "# 조기 종료를 위한 EarlyStopping을 정의합니다.\n",
    "# LSTM 모델을 훈련합니다.\n",
    "# 모델을 사용하여 예측을 수행합니다.\n",
    "# 평균 제곱 오차를 계산합니다.\n",
    "# 위의 코드를 실행하면 LSTM 모델을 사용하여 데이터를 훈련하고 예측하며, 평균 제곱 오차를 출력합니다.\n",
    "\n",
    "# 해당 모델은 주어진 특성(feature)들을 사용하여 주어진 시간에 대한\n",
    "# 배의 위도(latitude), 경도(longitude), Course Over Ground (COG), Speed Over Ground (SOG)를 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('linear_regression_model_Lstm.pkl', 'wb') as file:\n",
    "    pickle.dump(model_LSTRM, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델을 불러오기 위해 pickle 파일을 엽니다.\n",
    "model = pickle.load(open('linear_regression_model_Lstm.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/%EC%88%98%EC%A0%95LSTM.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# LSTM 모델과 스케일러를 로드합니다.\n",
    "with open('D:/장우영/LOCALSEARCH/Ship_DA/DA/model/linear_regression_model_Lstm.pkl', 'rb') as f:\n",
    "    model_LSTRM = pickle.load(f)\n",
    "\n",
    "with open('D:/장우영/LOCALSEARCH/Ship_DA/DA/model/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "\n",
    "@app.route('/api02/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # POST 요청에서 데이터를 가져옵니다.\n",
    "    data = request.json\n",
    "    \n",
    "    # 데이터 전처리를 수행합니다.\n",
    "    df = pd.DataFrame([data])  # 데이터를 리스트로 감싸서 단일 행의 DataFrame을 생성합니다.\n",
    "    df['minute'] = pd.to_datetime(df['insert_time']).dt.minute + 1\n",
    "    df['insert_time'] = pd.to_datetime(df['insert_time']) + pd.DateOffset(minutes=1)\n",
    "    X = df[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "    \n",
    "    # LSTM 모델을 사용하여 예측을 수행합니다.\n",
    "    y_pred = model_LSTRM.predict(X_reshaped)\n",
    "    \n",
    "    # 예측 결과를 리스트로 변환합니다.\n",
    "    y_pred_list = y_pred.tolist()\n",
    "    \n",
    "    # 응답용 JSON을 생성합니다.\n",
    "    response = {\n",
    "        \"latitude\": y_pred_list[0][0],\n",
    "        \"longitude\": y_pred_list[0][1],\n",
    "        \"predicted_cog\": y_pred_list[0][2],\n",
    "        \"predicted_sog\": y_pred_list[0][3]\n",
    "    }\n",
    "    \n",
    "    # JSON 형태로 응답을 반환합니다.\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 유효성 검사 손실 곡선을 그리기\n",
    "##### 2. 손실 곡선은 모델 성능에 대한 귀중한 통찰력을 제공하고 과적합과 같은 잠재적인 문제를 식별\n",
    "##### 3. training loss가 꾸준히 감소하고 validation loss도 함께 감소"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/LSTM%EC%86%90%EC%8B%A4%EA%B3%A1%EC%84%A0.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/LSTM%EC%8B%9C%EA%B0%81%ED%99%94.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 \n",
    "\n",
    "##### 해당 데이터 학습 이전 AIS 데이터의 속도 데이터가 정박에 정착해있는 sog=0인 데이터가 많음 => 모델이 데이터를 읽고 학습하기 이전에 sog>3 이라는 조건을 추가함\n",
    "\n",
    "##### LSTM 모델을 사용하니 정확도가 올라감 \n",
    "\n",
    "##### 0.9281195373257797 값은 주어진 코드에서 예측 값(y_pred)과 실제 값(y_test) 사이의 R 제곱 값입니다. 독립 변수에서 예측 가능한 종속 변수의 분산 비율을 나타냅니다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 3) LSTM+CNN 회귀 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "3842/3842 [==============================] - 22s 5ms/step - loss: 31.7209 - val_loss: 0.0634\n",
      "Epoch 2/30\n",
      "3842/3842 [==============================] - 21s 5ms/step - loss: 0.0600 - val_loss: 0.0629\n",
      "Epoch 3/30\n",
      "3842/3842 [==============================] - 21s 5ms/step - loss: 0.0586 - val_loss: 0.0611\n",
      "Epoch 4/30\n",
      "3842/3842 [==============================] - 22s 6ms/step - loss: 0.0587 - val_loss: 0.0623\n",
      "Epoch 5/30\n",
      "3842/3842 [==============================] - 22s 6ms/step - loss: 0.0586 - val_loss: 0.0618\n",
      "Epoch 6/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.6734 - val_loss: 0.0632\n",
      "Epoch 7/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.0585 - val_loss: 0.0606\n",
      "Epoch 8/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.0584 - val_loss: 0.0605\n",
      "Epoch 9/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0584 - val_loss: 0.0606\n",
      "Epoch 10/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0591 - val_loss: 0.0614\n",
      "Epoch 11/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0583 - val_loss: 0.0605\n",
      "Epoch 12/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0586 - val_loss: 0.0629\n",
      "Epoch 13/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0586 - val_loss: 0.0613\n",
      "Epoch 14/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0584 - val_loss: 0.0607\n",
      "Epoch 15/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.0586 - val_loss: 0.0605\n",
      "Epoch 16/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 0.0584 - val_loss: 0.0604\n",
      "Epoch 17/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0585 - val_loss: 0.0608\n",
      "Epoch 18/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.0585 - val_loss: 0.0607\n",
      "Epoch 19/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 0.0584 - val_loss: 0.0603\n",
      "Epoch 20/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0583 - val_loss: 0.0621\n",
      "Epoch 21/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0585 - val_loss: 0.0604\n",
      "Epoch 22/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0585 - val_loss: 0.0607\n",
      "Epoch 23/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0584 - val_loss: 0.0631\n",
      "Epoch 24/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0585 - val_loss: 0.0604\n",
      "Epoch 25/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0585 - val_loss: 0.0657\n",
      "Epoch 26/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0584 - val_loss: 0.0605\n",
      "Epoch 27/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0584 - val_loss: 0.0604\n",
      "Epoch 28/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0585 - val_loss: 0.0604\n",
      "Epoch 29/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0585 - val_loss: 0.0605\n",
      "Epoch 30/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0584 - val_loss: 0.0603\n",
      "Epoch 1/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 2622.4556 - val_loss: 0.3979\n",
      "Epoch 2/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0888 - val_loss: 0.0788\n",
      "Epoch 3/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0766 - val_loss: 0.0788\n",
      "Epoch 4/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0770 - val_loss: 0.0790\n",
      "Epoch 5/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0776 - val_loss: 0.0803\n",
      "Epoch 6/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0894\n",
      "Epoch 7/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0776 - val_loss: 0.0791\n",
      "Epoch 8/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0792\n",
      "Epoch 9/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0777 - val_loss: 0.0794\n",
      "Epoch 10/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0779 - val_loss: 0.0790\n",
      "Epoch 11/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0788\n",
      "Epoch 12/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0778 - val_loss: 0.0806\n",
      "Epoch 13/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0778 - val_loss: 0.0788\n",
      "Epoch 14/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0780 - val_loss: 0.0796\n",
      "Epoch 15/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0777 - val_loss: 0.0797\n",
      "Epoch 16/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0791\n",
      "Epoch 17/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0776 - val_loss: 0.0803\n",
      "Epoch 18/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0777 - val_loss: 0.0800\n",
      "Epoch 19/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0780 - val_loss: 0.0791\n",
      "Epoch 20/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0789\n",
      "Epoch 21/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0777 - val_loss: 0.0828\n",
      "Epoch 22/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0779 - val_loss: 0.0788\n",
      "Epoch 23/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0790\n",
      "Epoch 24/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0777 - val_loss: 0.0806\n",
      "Epoch 25/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0778 - val_loss: 0.0793\n",
      "Epoch 26/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0777 - val_loss: 0.0802\n",
      "Epoch 27/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0778 - val_loss: 0.0799\n",
      "Epoch 28/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0777 - val_loss: 0.0788\n",
      "Epoch 29/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0778 - val_loss: 0.0796\n",
      "Epoch 30/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0779 - val_loss: 0.0806\n",
      "Epoch 1/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 16976.5781 - val_loss: 10448.7168\n",
      "Epoch 2/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 10459.8291 - val_loss: 10388.1406\n",
      "Epoch 3/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 10475.5586 - val_loss: 10383.5537\n",
      "Epoch 4/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 9773.0801 - val_loss: 3535.0120\n",
      "Epoch 5/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 549.8472 - val_loss: 44.8096\n",
      "Epoch 6/30\n",
      "3842/3842 [==============================] - 27s 7ms/step - loss: 15.4050 - val_loss: 3.1154\n",
      "Epoch 7/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 4.2209 - val_loss: 1.1770\n",
      "Epoch 8/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 2.2419 - val_loss: 8.3916\n",
      "Epoch 9/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 1.4677 - val_loss: 0.5291\n",
      "Epoch 10/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 1.1178 - val_loss: 0.6321\n",
      "Epoch 11/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.9894 - val_loss: 2.4476\n",
      "Epoch 12/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 0.8712 - val_loss: 0.4649\n",
      "Epoch 13/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.6938 - val_loss: 0.2778\n",
      "Epoch 14/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.6526 - val_loss: 0.5965\n",
      "Epoch 15/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.5198 - val_loss: 0.6502\n",
      "Epoch 16/30\n",
      "3842/3842 [==============================] - 25s 7ms/step - loss: 0.4766 - val_loss: 0.1265\n",
      "Epoch 17/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.3964 - val_loss: 0.1042\n",
      "Epoch 18/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.4579 - val_loss: 0.1176\n",
      "Epoch 19/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.3716 - val_loss: 0.1306\n",
      "Epoch 20/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.3246 - val_loss: 0.0858\n",
      "Epoch 21/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.3010 - val_loss: 0.1816\n",
      "Epoch 22/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.2362 - val_loss: 0.1194\n",
      "Epoch 23/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.2484 - val_loss: 0.5605\n",
      "Epoch 24/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.2328 - val_loss: 0.5417\n",
      "Epoch 25/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.2061 - val_loss: 0.1657\n",
      "Epoch 26/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.4949 - val_loss: 0.0967\n",
      "Epoch 27/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.2039 - val_loss: 0.3220\n",
      "Epoch 28/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.1734 - val_loss: 0.3154\n",
      "Epoch 29/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.1789 - val_loss: 0.0739\n",
      "Epoch 30/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.1833 - val_loss: 0.1133\n",
      "Epoch 1/30\n",
      "3842/3842 [==============================] - 26s 6ms/step - loss: 15.8494 - val_loss: 15.0799\n",
      "Epoch 2/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 13.4881 - val_loss: 3.5046\n",
      "Epoch 3/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 1.1903 - val_loss: 0.2900\n",
      "Epoch 4/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0758 - val_loss: 0.0728\n",
      "Epoch 5/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0386 - val_loss: 0.0575\n",
      "Epoch 6/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0299 - val_loss: 0.0497\n",
      "Epoch 7/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0246 - val_loss: 0.0471\n",
      "Epoch 8/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0229 - val_loss: 0.0522\n",
      "Epoch 9/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0177 - val_loss: 0.1880\n",
      "Epoch 10/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0188 - val_loss: 0.0383\n",
      "Epoch 11/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0134 - val_loss: 0.0393\n",
      "Epoch 12/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0164 - val_loss: 0.0408\n",
      "Epoch 13/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.0151 - val_loss: 0.0365\n",
      "Epoch 14/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0103 - val_loss: 0.0494\n",
      "Epoch 15/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0127 - val_loss: 0.0387\n",
      "Epoch 16/30\n",
      "3842/3842 [==============================] - 23s 6ms/step - loss: 0.0100 - val_loss: 0.0379\n",
      "Epoch 17/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0094 - val_loss: 0.0352\n",
      "Epoch 18/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0089 - val_loss: 0.0488\n",
      "Epoch 19/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0071 - val_loss: 0.0354\n",
      "Epoch 20/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0072 - val_loss: 0.0397\n",
      "Epoch 21/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0073 - val_loss: 0.0321\n",
      "Epoch 22/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0060 - val_loss: 0.0509\n",
      "Epoch 23/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0064 - val_loss: 0.0317\n",
      "Epoch 24/30\n",
      "3842/3842 [==============================] - 24s 6ms/step - loss: 0.0057 - val_loss: 0.0314\n",
      "Epoch 25/30\n",
      "3842/3842 [==============================] - 25s 6ms/step - loss: 0.0049 - val_loss: 0.0423\n",
      "Epoch 26/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.0041 - val_loss: 0.0309\n",
      "Epoch 27/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.0042 - val_loss: 0.0325\n",
      "Epoch 28/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.0048 - val_loss: 0.0325\n",
      "Epoch 29/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.0035 - val_loss: 0.0321\n",
      "Epoch 30/30\n",
      "3842/3842 [==============================] - 26s 7ms/step - loss: 0.0039 - val_loss: 0.0319\n",
      "961/961 [==============================] - 3s 3ms/step\n",
      "961/961 [==============================] - 3s 2ms/step\n",
      "961/961 [==============================] - 3s 3ms/step\n",
      "961/961 [==============================] - 3s 3ms/step\n",
      "Mean Squared Error - Latitude: 0.060318085810021356\n",
      "Mean Squared Error - Longitude: 0.08056472066281514\n",
      "Mean Squared Error - COG: 0.11326184436024221\n",
      "Mean Squared Error - SOG: 0.03185195181749647\n",
      "{'latitude': 35.00629806518555, 'longitude': 129.19781494140625, 'predicted_cog': 121.34892272949219, 'predicted_sog': 6.833309650421143}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LSTM + CNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Conv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pyproj import Transformer\n",
    "\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "\n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱 \n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "\n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/Ship_DA/DA/data/FAmerge_20230607_114714.csv', encoding='ANSI')\n",
    "\n",
    "# 특정 칼럼의 조건에 따라 데이터 필터링\n",
    "filtered_data = data[data['sog'] > 3]  # 특정 칼럼과 조건을 적절히 수정해야 합니다\n",
    "\n",
    "data= filtered_data\n",
    "\n",
    "\n",
    "# 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "#print(data[['latitude', 'longitude']])\n",
    "\n",
    "# \"insert_time\"을 숫자로 변환\n",
    "data['year'] = pd.to_datetime(data['insert_time']).dt.year\n",
    "data['month'] = pd.to_datetime(data['insert_time']).dt.month\n",
    "data['day'] = pd.to_datetime(data['insert_time']).dt.day\n",
    "data['hour'] = pd.to_datetime(data['insert_time']).dt.hour\n",
    "data['minute'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "data['second'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "\n",
    "\n",
    "# 특성과 타겟 변수 선택\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "X['minute'] = pd.to_datetime(data['insert_time']).dt.minute + 1\n",
    "y = data[[\"latitude\", \"longitude\",\"cog\", \"sog\"]]\n",
    "\n",
    "print(X)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MinMaxScaler를 사용하여 입력 특성 스케일 조정\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LSTM에 맞게 입력 데이터 형태 변환\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "\n",
    "# LSTM과 CNN을 결합한 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# Conv1D 레이어를 추가합니다. 1D 컨볼루션 연산을 수행하는 레이어로, 입력 데이터의 필터 수는 64개, 커널 크기는 3입니다. 활성화 함수로는 ReLU를 사용하고, 입력 형태는 X_train_reshaped의 shape[1]과 shape[2]에 해당합니다.\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "\n",
    "#  LSTM은 순환 신경망의 한 종류로, 입력 데이터에 대한 장기 의존성을 모델링하는 데 사용됩니다. 이 레이어의 뉴런 수는 64개    \n",
    "model.add(LSTM(64))\n",
    "\n",
    "# Dense 레이어를 추가합니다. 출력층으로 사용되며, 뉴런 수는 4개입니다. 이 뉴런은 (latitude, longitude, sog, cog)와 같은 4개의 출력 값을 예측하는 데 사용\n",
    "model.add(Dense(4))  \n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 조기 종료를 위한 EarlyStopping 정의\n",
    "#early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=50, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to a list\n",
    "y_pred_list = y_pred.tolist()\n",
    "\n",
    "# 평균 제곱 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# y_test(실제 값)와 y_pred(예측 값) 사이의 R-제곱 값을 계산\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared:\", r2)\n",
    "\n",
    "# Create the response JSON\n",
    "response = {\n",
    "    \"latitude\": y_pred_list[0][0],\n",
    "    \"longitude\": y_pred_list[0][1],\n",
    "    \"predicted_cog\": y_pred_list[0][2],\n",
    "    \"predicted_sog\": y_pred_list[0][3]\n",
    "}\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/LSTM%2BCNN%EA%B2%B0%EA%B3%BC%EA%B0%92.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/LSTM%2BCNN%EC%86%90%EC%8B%A4%EA%B3%A1%EC%84%A0.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/LSTM%2BCNN%EA%B2%B0%EA%B3%BC%20%EC%8B%9C%EA%B0%81%ED%99%94.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('linear_regression_model_Lstm_CNN.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "    \n",
    "\n",
    "# 모델을 불러오기 위해 pickle 파일을 엽니다.\n",
    "model = pickle.load(open('linear_regression_model_Lstm_CNN.pkl', 'rb'))\n",
    "\n",
    "\n",
    "# Save the scaler object\n",
    "with open('scaler_LC.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "# Load the scaler object\n",
    "loaded_scaler = pickle.load(open('scaler_LC.pkl', 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결과\n",
    "\n",
    "##### 1. LSTM+CNN 모델은 일반적으로 피드포워드 신경망과 같은 단순한 모델보다 더 복잡하여 교육 시간이 길어짐\n",
    "\n",
    "##### 2. 많은 시간 단계: LSTM+CNN 모델은 이러한 단계에서 정보를 처리하고 전파해야 하므로 계산 비용과 시간이 많이 소요\n",
    "\n",
    "##### 3. 정확도가 낮음 66퍼센트 확률 \n",
    "\n",
    "##### => epochs 수행 속도를 30에서 50으로 설정,  sog>3인 데이터만 추출하여 학습 진행\n",
    "##### => 학습시간: 23분=>34분 ,   정확도: 66%=> 97% =>하지만 정확한 예측이 이루어지지 않음 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04) GradientBoostingRegressor 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mmsi  ship_type   latitude   longitude    cog   sog  year  month   \n",
      "0      440051540          0  35.039909  129.062547  329.2   5.7  2023      5  \\\n",
      "5      538010219          0  34.882612  129.060553  212.2  16.1  2023      5   \n",
      "17     440051540          0  35.039909  129.062547  329.2   5.7  2023      5   \n",
      "19     440102990          0  35.099860  129.041436   42.6   8.8  2023      5   \n",
      "20     440048210         80  35.064618  129.110167   31.6   9.6  2023      5   \n",
      "...          ...        ...        ...         ...    ...   ...   ...    ...   \n",
      "52705  440135680          0  34.958493  129.193000  306.5  10.1  2023      5   \n",
      "52708  440658000         70  35.042145  129.170300  239.4   7.5  2023      5   \n",
      "52709  440761000         71  35.019416  129.126246  210.0   7.6  2023      5   \n",
      "52714  440003510          0  35.035548  129.038131   90.6  15.3  2023      5   \n",
      "52726  563156900         71  34.813431  129.000033   49.5  11.8  2023      5   \n",
      "\n",
      "       day  hour  minute  second   풍향   유향    기온    수온    풍속   유속    기압  습도  \n",
      "0       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "5       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "17      11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "19      11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "20      11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "...    ...   ...     ...     ...  ...  ...   ...   ...   ...  ...   ...  ..  \n",
      "52705   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52708   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52709   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52714   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52726   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "\n",
      "[16176 rows x 20 columns]\n",
      "Predicted Latitude: [34.96951718 35.08868567 35.10173364 ... 34.95655137 35.14399455\n",
      " 35.0394915 ]\n",
      "Predicted Longitude: [129.18652836 129.08581253 129.08412821 ... 129.07487267 129.38044052\n",
      " 128.99520569]\n",
      "Predicted COG: [235.75359672 305.84701441  86.07258449 ... 345.83881223 217.83442507\n",
      " 305.85237338]\n",
      "Predicted SOG: [10.79892935 15.47186304  5.33367334 ... 10.12397026 11.20140178\n",
      "  9.99407227]\n",
      "MSE Latitude: 9.405765758571101e-06\n",
      "MSE Longitude: 1.4935029686658968e-05\n",
      "MSE COG: 0.44365972933018827\n",
      "MSE SOG: 0.0006323589681708897\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "from pyproj import Transformer\n",
    "\n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱\n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        #transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "   \n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "# Load data from CSV file\n",
    "data = pd.read_csv('D:/장우영/LOCALSEARCH/Ship_DA/DA/data/FAmerge_20230607_1147142.csv', encoding='ANSI')\n",
    "\n",
    "# 특정 칼럼의 조건에 따라 데이터 필터링\n",
    "filtered_data = data[data['sog'] > 3]  # 특정 칼럼과 조건을 적절히 수정해야 합니다\n",
    "\n",
    "data= filtered_data\n",
    "\n",
    "# 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "# \"insert_time\"을 숫자로 변환\n",
    "data['year'] = pd.to_datetime(data['insert_time']).dt.year\n",
    "data['month'] = pd.to_datetime(data['insert_time']).dt.month\n",
    "data['day'] = pd.to_datetime(data['insert_time']).dt.day\n",
    "data['hour'] = pd.to_datetime(data['insert_time']).dt.hour\n",
    "data['minute'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "data['second'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "\n",
    "# 특성 선택\n",
    "\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\",\"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "\n",
    "print(X)\n",
    "\n",
    "# 타겟 변수 선택\n",
    "y_latitude = data[\"latitude\"]  # 원래 데이터셋의 Latitude 값\n",
    "y_longitude = data[\"longitude\"]  # 원래 데이터셋의 Longitude 값\n",
    "y_cog = data[\"cog\"]  # 원래 데이터셋의 COG 값\n",
    "y_sog = data[\"sog\"]  # 원래 데이터셋의 SOG 값\n",
    "\n",
    "# 데이터를 교육 및 테스트 세트로 분할\n",
    "X_train, X_test, y_latitude_train, y_latitude_test, y_longitude_train, y_longitude_test, y_cog_train, y_cog_test, y_sog_train, y_sog_test = train_test_split(\n",
    "    X, y_latitude, y_longitude, y_cog, y_sog, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Latitude 모델 훈련 및 예측\n",
    "model_latitude = GradientBoostingRegressor()\n",
    "model_latitude.fit(X_train, y_latitude_train)\n",
    "y_latitude_pred = model_latitude.predict(X_test)\n",
    "\n",
    "# Longitude 모델 훈련 및 예측\n",
    "model_longitude = GradientBoostingRegressor()\n",
    "model_longitude.fit(X_train, y_longitude_train)\n",
    "y_longitude_pred = model_longitude.predict(X_test)\n",
    "\n",
    "# COG 모델 훈련 및 예측\n",
    "model_cog = GradientBoostingRegressor()\n",
    "model_cog.fit(X_train, y_cog_train)\n",
    "y_cog_pred = model_cog.predict(X_test)\n",
    "\n",
    "# SOG 모델 훈련 및 예측\n",
    "model_sog = GradientBoostingRegressor()\n",
    "model_sog.fit(X_train, y_sog_train)\n",
    "y_sog_pred = model_sog.predict(X_test)\n",
    "\n",
    "# 정확도 예측\n",
    "mse_latitude = mean_squared_error(y_latitude_test, y_latitude_pred)\n",
    "mse_longitude = mean_squared_error(y_longitude_test, y_longitude_pred)\n",
    "mse_cog = mean_squared_error(y_cog_test, y_cog_pred)\n",
    "mse_sog = mean_squared_error(y_sog_test, y_sog_pred)\n",
    "\n",
    "# 예측된 Latitude, Longitude, COG, SOG 값을 출력\n",
    "print(\"Predicted Latitude:\", y_latitude_pred)\n",
    "print(\"Predicted Longitude:\", y_longitude_pred)\n",
    "print(\"Predicted COG:\", y_cog_pred)\n",
    "print(\"Predicted SOG:\", y_sog_pred)\n",
    "\n",
    "# 정확도 예측\n",
    "print(\"MSE Latitude:\", mse_latitude)\n",
    "print(\"MSE Longitude:\", mse_longitude)\n",
    "print(\"MSE COG:\", mse_cog)\n",
    "print(\"MSE SOG:\", mse_sog)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create DataFrames for the actual and predicted values.\n",
    "predictions_latitude = pd.DataFrame({'Actual Latitude': y_latitude_test, 'Predicted Latitude': y_latitude_pred})\n",
    "predictions_longitude = pd.DataFrame({'Actual Longitude': y_longitude_test, 'Predicted Longitude': y_longitude_pred})\n",
    "predictions_cog = pd.DataFrame({'Actual COG': y_cog_test, 'Predicted COG': y_cog_pred})\n",
    "predictions_sog = pd.DataFrame({'Actual SOG': y_sog_test, 'Predicted SOG': y_sog_pred})\n",
    "\n",
    "# Sort the DataFrames by the actual values to align the values.\n",
    "predictions_latitude = predictions_latitude.sort_values('Actual Latitude')\n",
    "predictions_longitude = predictions_longitude.sort_values('Actual Longitude')\n",
    "predictions_cog = predictions_cog.sort_values('Actual COG')\n",
    "predictions_sog = predictions_sog.sort_values('Actual SOG')\n",
    "\n",
    "# Generate line plots for latitude, longitude, COG, and SOG.\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(8, 12))\n",
    "\n",
    "# Latitude\n",
    "axes[0].plot(predictions_latitude.index, predictions_latitude['Actual Latitude'], label='Actual Latitude')\n",
    "axes[0].plot(predictions_latitude.index, predictions_latitude['Predicted Latitude'], label='Predicted Latitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "axes[0].set_title('Actual vs Predicted Latitude')\n",
    "axes[0].legend()\n",
    "\n",
    "# Longitude\n",
    "axes[1].plot(predictions_longitude.index, predictions_longitude['Actual Longitude'], label='Actual Longitude')\n",
    "axes[1].plot(predictions_longitude.index, predictions_longitude['Predicted Longitude'], label='Predicted Longitude')\n",
    "axes[1].set_ylabel('Longitude')\n",
    "axes[1].set_title('Actual vs Predicted Longitude')\n",
    "axes[1].legend()\n",
    "\n",
    "# COG\n",
    "axes[2].plot(predictions_cog.index, predictions_cog['Actual COG'], label='Actual COG')\n",
    "axes[2].plot(predictions_cog.index, predictions_cog['Predicted COG'], label='Predicted COG')\n",
    "axes[2].set_ylabel('COG')\n",
    "axes[2].set_title('Actual vs Predicted COG')\n",
    "axes[2].legend()\n",
    "\n",
    "# SOG\n",
    "axes[3].plot(predictions_sog.index, predictions_sog['Actual SOG'], label='Actual SOG')\n",
    "axes[3].plot(predictions_sog.index, predictions_sog['Predicted SOG'], label='Predicted SOG')\n",
    "axes[3].set_xlabel('Index')\n",
    "axes[3].set_ylabel('SOG')\n",
    "axes[3].set_title('Actual vs Predicted SOG')\n",
    "axes[3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../data_image/06.15.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](\"D:\\장우영\\LOCALSEARCH\\Ship_DA\\DA\\data_image\\06.15.PNG\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 1시간의 데이터가 아닌 7시간의 데이터를 학습모델의 데이터로 사용\n",
    "#### 2. 예측하고 하는 latitude, longitude, cog, sog의 값을 각각으 모델로 만들어 정확도를 높임 \n",
    "#### 3.추가적으로 sog>3 , 하루치 데이터 학습\n",
    "\n",
    "\n",
    "분석 결과, 위도와 경도의 예측 값의 MSE가 매우 작아 정확한 예측이 이루어졌지만, COG와 SOG의 예측 값의 MSE가 상대적으로 크므로 해당 변수들을 예측하는 데는 아직 개선의 여지가 있을 수 있습니다. 추가적인 데이터 처리나 모델 튜닝 등을 통해 모델의 성능을 더욱 개선할 수 있을 것입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
