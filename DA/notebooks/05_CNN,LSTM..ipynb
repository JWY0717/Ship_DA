{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            mmsi  ship_type   latitude   longitude    cog   sog  year  month   \n",
      "0      440051540          0  35.039909  129.062547  329.2   5.7  2023      5  \\\n",
      "5      538010219          0  34.882612  129.060553  212.2  16.1  2023      5   \n",
      "17     440051540          0  35.039909  129.062547  329.2   5.7  2023      5   \n",
      "19     440102990          0  35.099860  129.041436   42.6   8.8  2023      5   \n",
      "20     440048210         80  35.064618  129.110167   31.6   9.6  2023      5   \n",
      "...          ...        ...        ...         ...    ...   ...   ...    ...   \n",
      "52705  440135680          0  34.958493  129.193000  306.5  10.1  2023      5   \n",
      "52708  440658000         70  35.042145  129.170300  239.4   7.5  2023      5   \n",
      "52709  440761000         71  35.019416  129.126246  210.0   7.6  2023      5   \n",
      "52714  440003510          0  35.035548  129.038131   90.6  15.3  2023      5   \n",
      "52726  563156900         71  34.813431  129.000033   49.5  11.8  2023      5   \n",
      "\n",
      "       day  hour  minute  second   풍향   유향    기온    수온    풍속   유속    기압  습도  \n",
      "0       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "5       11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "17      11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "19      11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "20      11    10      10      10  196  246  16.4  17.0  9.77  0.3  1017  82  \n",
      "...    ...   ...     ...     ...  ...  ...   ...   ...   ...  ...   ...  ..  \n",
      "52705   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52708   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52709   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52714   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "52726   11    11      19      19  191  249  16.4  16.6  9.25  0.1  1017  80  \n",
      "\n",
      "[16176 rows x 20 columns]\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 4s 6ms/step - loss: 11799.0508 - val_loss: 9976.3184\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 8643.6113 - val_loss: 7474.6309\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 6547.3398 - val_loss: 5718.0767\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 5084.2690 - val_loss: 4506.5337\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4098.3804 - val_loss: 3710.3733\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3468.8198 - val_loss: 3216.2883\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3091.4033 - val_loss: 2928.5100\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2882.4910 - val_loss: 2775.6777\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2777.0210 - val_loss: 2701.7737\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2729.6716 - val_loss: 2669.9021\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2712.0242 - val_loss: 2658.3940\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2706.2261 - val_loss: 2654.6951\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.5835 - val_loss: 2653.2935\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2219 - val_loss: 2653.2371\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2197 - val_loss: 2652.9207\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2114 - val_loss: 2652.9863\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.1472 - val_loss: 2652.8647\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2158 - val_loss: 2652.9082\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.1692 - val_loss: 2652.7969\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 2704.2151 - val_loss: 2652.8760\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2273 - val_loss: 2653.1069\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2524 - val_loss: 2653.1201\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 2704.3789 - val_loss: 2652.8621\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2173 - val_loss: 2652.8140\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2021 - val_loss: 2653.0725\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.3013 - val_loss: 2653.0491\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2476 - val_loss: 2652.7268\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2346 - val_loss: 2652.7429\n",
      "Epoch 29/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.3540 - val_loss: 2652.8811\n",
      "Epoch 30/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.1479 - val_loss: 2652.7756\n",
      "Epoch 31/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2466 - val_loss: 2652.9080\n",
      "Epoch 32/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.3179 - val_loss: 2653.0386\n",
      "Epoch 33/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2695 - val_loss: 2652.9189\n",
      "Epoch 34/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2402 - val_loss: 2652.9880\n",
      "Epoch 35/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2019 - val_loss: 2653.2590\n",
      "Epoch 36/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2520 - val_loss: 2652.9004\n",
      "Epoch 37/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2769 - val_loss: 2652.9629\n",
      "Epoch 38/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2090 - val_loss: 2652.8218\n",
      "Epoch 39/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.2954 - val_loss: 2652.9512\n",
      "Epoch 40/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2704.4285 - val_loss: 2652.5151\n",
      "Epoch 41/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2703.3679 - val_loss: 2651.5188\n",
      "Epoch 42/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2702.7913 - val_loss: 2651.3176\n",
      "Epoch 43/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2702.2615 - val_loss: 2650.9270\n",
      "Epoch 44/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2701.4548 - val_loss: 2650.8352\n",
      "Epoch 45/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2701.2188 - val_loss: 2650.4480\n",
      "Epoch 46/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2700.5320 - val_loss: 2650.2568\n",
      "Epoch 47/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2700.4539 - val_loss: 2651.9443\n",
      "Epoch 48/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2700.5791 - val_loss: 2650.2920\n",
      "Epoch 49/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2700.0225 - val_loss: 2650.7632\n",
      "Epoch 50/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2700.2263 - val_loss: 2650.1980\n",
      "Epoch 51/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.9189 - val_loss: 2650.6638\n",
      "Epoch 52/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2700.0283 - val_loss: 2650.2104\n",
      "Epoch 53/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.8552 - val_loss: 2650.9827\n",
      "Epoch 54/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.9690 - val_loss: 2650.3650\n",
      "Epoch 55/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.7739 - val_loss: 2650.7065\n",
      "Epoch 56/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.9036 - val_loss: 2650.3579\n",
      "Epoch 57/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.6426 - val_loss: 2650.3022\n",
      "Epoch 58/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2699.5298 - val_loss: 2650.1418\n",
      "Epoch 59/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2442.0466 - val_loss: 1482.8209\n",
      "Epoch 60/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1074.4341 - val_loss: 751.9120\n",
      "Epoch 61/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 586.4745 - val_loss: 441.6921\n",
      "Epoch 62/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 349.4997 - val_loss: 273.4533\n",
      "Epoch 63/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 221.7302 - val_loss: 178.9101\n",
      "Epoch 64/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 144.2605 - val_loss: 120.7012\n",
      "Epoch 65/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 92.2229 - val_loss: 72.5749\n",
      "Epoch 66/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 62.1534 - val_loss: 47.7592\n",
      "Epoch 67/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 40.7367 - val_loss: 32.3104\n",
      "Epoch 68/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 27.3481 - val_loss: 22.8668\n",
      "Epoch 69/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 19.2281 - val_loss: 20.0237\n",
      "Epoch 70/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 13.6312 - val_loss: 11.0400\n",
      "Epoch 71/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 10.0462 - val_loss: 9.1361\n",
      "Epoch 72/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 7.5888 - val_loss: 6.3072\n",
      "Epoch 73/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 6.5507 - val_loss: 6.2703\n",
      "Epoch 74/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 7.9054 - val_loss: 5.5867\n",
      "Epoch 75/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.5416 - val_loss: 4.6349\n",
      "Epoch 76/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.3400 - val_loss: 5.0313\n",
      "Epoch 77/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.5933 - val_loss: 4.3768\n",
      "Epoch 78/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.9936 - val_loss: 5.0442\n",
      "Epoch 79/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.1546 - val_loss: 3.7279\n",
      "Epoch 80/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.8234 - val_loss: 6.7475\n",
      "Epoch 81/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.0083 - val_loss: 3.5846\n",
      "Epoch 82/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.3947 - val_loss: 3.4464\n",
      "Epoch 83/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.5894 - val_loss: 4.3228\n",
      "Epoch 84/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.8786 - val_loss: 3.7266\n",
      "Epoch 85/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.2607 - val_loss: 3.7547\n",
      "Epoch 86/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.6294 - val_loss: 3.4724\n",
      "Epoch 87/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2.9060 - val_loss: 3.1911\n",
      "Epoch 88/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2.9020 - val_loss: 2.8168\n",
      "Epoch 89/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2.4254 - val_loss: 3.1772\n",
      "Epoch 90/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2.5471 - val_loss: 2.0249\n",
      "Epoch 91/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2.3657 - val_loss: 1.9101\n",
      "Epoch 92/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 2.1945 - val_loss: 4.4901\n",
      "Epoch 93/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.9071 - val_loss: 1.7984\n",
      "Epoch 94/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.5956 - val_loss: 3.5935\n",
      "Epoch 95/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.9740 - val_loss: 1.1688\n",
      "Epoch 96/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.4640 - val_loss: 1.0938\n",
      "Epoch 97/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.4508 - val_loss: 1.1867\n",
      "Epoch 98/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.3348 - val_loss: 0.9945\n",
      "Epoch 99/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.2489 - val_loss: 1.1182\n",
      "Epoch 100/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1.4666 - val_loss: 1.0889\n",
      "102/102 [==============================] - 0s 2ms/step\n",
      "Mean Squared Error: 1.0888897231293289\n",
      "{'latitude': 34.9339714050293, 'longitude': 129.0572052001953, 'predicted_cog': 234.74525451660156, 'predicted_sog': 11.7249174118042}\n"
     ]
    }
   ],
   "source": [
    "# LSTM + CNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Conv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pyproj import Transformer\n",
    "\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "\n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱 \n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "\n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "data = pd.read_csv('D:\\\\장우영\\\\LOCALSEARCH\\\\DA\\\\DA\\\\data\\\\FAmerge_20230531_103345.csv', encoding='ANSI')\n",
    "\n",
    "# 특정 칼럼의 조건에 따라 데이터 필터링\n",
    "filtered_data = data[data['sog'] > 3]  # 특정 칼럼과 조건을 적절히 수정해야 합니다\n",
    "\n",
    "data= filtered_data\n",
    "\n",
    "\n",
    "# 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "#print(data[['latitude', 'longitude']])\n",
    "\n",
    "# \"insert_time\"을 숫자로 변환\n",
    "data['year'] = pd.to_datetime(data['insert_time']).dt.year\n",
    "data['month'] = pd.to_datetime(data['insert_time']).dt.month\n",
    "data['day'] = pd.to_datetime(data['insert_time']).dt.day\n",
    "data['hour'] = pd.to_datetime(data['insert_time']).dt.hour\n",
    "data['minute'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "data['second'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "\n",
    "\n",
    "# 특성과 타겟 변수 선택\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "y = data[[\"latitude\", \"longitude\",\"cog\", \"sog\"]]\n",
    "\n",
    "print(X)\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# MinMaxScaler를 사용하여 입력 특성 스케일 조정\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LSTM에 맞게 입력 데이터 형태 변환\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "\n",
    "# LSTM과 CNN을 결합한 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# Conv1D 레이어를 추가합니다. 1D 컨볼루션 연산을 수행하는 레이어로, 입력 데이터의 필터 수는 64개, 커널 크기는 3입니다. 활성화 함수로는 ReLU를 사용하고, 입력 형태는 X_train_reshaped의 shape[1]과 shape[2]에 해당합니다.\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "\n",
    "#  LSTM은 순환 신경망의 한 종류로, 입력 데이터에 대한 장기 의존성을 모델링하는 데 사용됩니다. 이 레이어의 뉴런 수는 64개    \n",
    "model.add(LSTM(64))\n",
    "\n",
    "# Dense 레이어를 추가합니다. 출력층으로 사용되며, 뉴런 수는 4개입니다. 이 뉴런은 (latitude, longitude, sog, cog)와 같은 4개의 출력 값을 예측하는 데 사용\n",
    "model.add(Dense(4))  \n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 조기 종료를 위한 EarlyStopping 정의\n",
    "#early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(X_train_reshaped, y_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_test))\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "y_pred = model.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to a list\n",
    "y_pred_list = y_pred.tolist()\n",
    "\n",
    "# 평균 제곱 오차 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Create the response JSON\n",
    "response = {\n",
    "    \"latitude\": y_pred_list[0][0],\n",
    "    \"longitude\": y_pred_list[0][1],\n",
    "    \"predicted_cog\": y_pred_list[0][2],\n",
    "    \"predicted_sog\": y_pred_list[0][3]\n",
    "}\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "405/405 [==============================] - 4s 6ms/step - loss: 255.4030 - val_loss: 21.4455\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 4.4122 - val_loss: 0.0821\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0235 - val_loss: 0.0140\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0141\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0142\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0143\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0139 - val_loss: 0.0140\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0139\n",
      "Epoch 29/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 30/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0147\n",
      "Epoch 31/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 32/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 33/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 34/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 35/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0139\n",
      "Epoch 36/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 37/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0144 - val_loss: 0.0143\n",
      "Epoch 38/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 39/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0164\n",
      "Epoch 40/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0145\n",
      "Epoch 41/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 42/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 43/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 44/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 45/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 46/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 47/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 48/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0147\n",
      "Epoch 49/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0138\n",
      "Epoch 50/100\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 51/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 52/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0144 - val_loss: 0.0162\n",
      "Epoch 53/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 54/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 55/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0143\n",
      "Epoch 56/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 57/100\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.0141 - val_loss: 0.0145\n",
      "Epoch 58/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0144 - val_loss: 0.0141\n",
      "Epoch 59/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 60/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0153\n",
      "Epoch 61/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 0.0141 - val_loss: 0.0175\n",
      "Epoch 62/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 63/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 64/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 65/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 66/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 0.0144 - val_loss: 0.0138\n",
      "Epoch 67/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 0.0141 - val_loss: 0.0149\n",
      "Epoch 68/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 0.0141 - val_loss: 0.0139\n",
      "Epoch 69/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0140\n",
      "Epoch 70/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0144 - val_loss: 0.0154\n",
      "Epoch 71/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0140\n",
      "Epoch 72/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0146\n",
      "Epoch 73/100\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.0142 - val_loss: 0.0167\n",
      "Epoch 74/100\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.0143 - val_loss: 0.0142\n",
      "Epoch 75/100\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 76/100\n",
      "405/405 [==============================] - 3s 7ms/step - loss: 0.0143 - val_loss: 0.0151\n",
      "Epoch 77/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0167\n",
      "Epoch 78/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0142\n",
      "Epoch 79/100\n",
      "405/405 [==============================] - 3s 6ms/step - loss: 0.0141 - val_loss: 0.0146\n",
      "Epoch 80/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 81/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0141 - val_loss: 0.0138\n",
      "Epoch 82/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0143 - val_loss: 0.0141\n",
      "Epoch 83/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 84/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 85/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0141 - val_loss: 0.0140\n",
      "Epoch 86/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0140 - val_loss: 0.0140\n",
      "Epoch 87/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0146\n",
      "Epoch 88/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0143\n",
      "Epoch 89/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0159\n",
      "Epoch 90/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0143 - val_loss: 0.0159\n",
      "Epoch 91/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0153\n",
      "Epoch 92/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 93/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0141\n",
      "Epoch 94/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0142 - val_loss: 0.0138\n",
      "Epoch 95/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0142\n",
      "Epoch 96/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0144\n",
      "Epoch 97/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0141 - val_loss: 0.0141\n",
      "Epoch 98/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0140 - val_loss: 0.0141\n",
      "Epoch 99/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0142 - val_loss: 0.0149\n",
      "Epoch 100/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0143 - val_loss: 0.0143\n",
      "Epoch 1/100\n",
      "405/405 [==============================] - 4s 6ms/step - loss: 11590.8467 - val_loss: 8738.7314\n",
      "Epoch 2/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 6720.5366 - val_loss: 4954.0269\n",
      "Epoch 3/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3685.2009 - val_loss: 2600.9419\n",
      "Epoch 4/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 1847.5376 - val_loss: 1221.7213\n",
      "Epoch 5/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 816.8057 - val_loss: 494.5253\n",
      "Epoch 6/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 306.1183 - val_loss: 164.7129\n",
      "Epoch 7/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 92.7010 - val_loss: 42.6866\n",
      "Epoch 8/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 21.4350 - val_loss: 8.0596\n",
      "Epoch 9/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 3.5505 - val_loss: 1.0359\n",
      "Epoch 10/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.4018 - val_loss: 0.0970\n",
      "Epoch 11/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0421 - val_loss: 0.0218\n",
      "Epoch 12/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0177 - val_loss: 0.0187\n",
      "Epoch 13/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 14/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 15/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 16/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 17/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 18/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 19/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 20/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 21/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 22/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0186\n",
      "Epoch 23/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 24/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0168 - val_loss: 0.0187\n",
      "Epoch 25/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 26/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 27/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 28/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 29/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0188\n",
      "Epoch 30/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 31/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 32/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0187\n",
      "Epoch 33/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0186\n",
      "Epoch 34/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0169 - val_loss: 0.0189\n",
      "Epoch 35/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0170 - val_loss: 0.0191\n",
      "Epoch 36/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0170 - val_loss: 0.0191\n",
      "Epoch 37/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0170 - val_loss: 0.0188\n",
      "Epoch 38/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0170 - val_loss: 0.0189\n",
      "Epoch 39/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0171 - val_loss: 0.0186\n",
      "Epoch 40/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0171 - val_loss: 0.0187\n",
      "Epoch 41/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0212\n",
      "Epoch 42/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 43/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0187\n",
      "Epoch 44/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0194\n",
      "Epoch 45/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0188\n",
      "Epoch 46/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 47/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0186\n",
      "Epoch 48/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 49/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0188\n",
      "Epoch 50/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0190\n",
      "Epoch 51/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 52/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 53/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0187\n",
      "Epoch 54/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0176 - val_loss: 0.0194\n",
      "Epoch 55/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0186\n",
      "Epoch 56/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 57/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0186\n",
      "Epoch 58/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0171 - val_loss: 0.0207\n",
      "Epoch 59/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 60/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0217\n",
      "Epoch 61/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 62/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 63/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0188\n",
      "Epoch 64/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0189\n",
      "Epoch 65/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0188\n",
      "Epoch 66/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 67/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0197\n",
      "Epoch 68/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0176 - val_loss: 0.0186\n",
      "Epoch 69/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0189\n",
      "Epoch 70/100\n",
      "405/405 [==============================] - 2s 4ms/step - loss: 0.0174 - val_loss: 0.0190\n",
      "Epoch 71/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0193\n",
      "Epoch 72/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0187\n",
      "Epoch 73/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0195\n",
      "Epoch 74/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0188\n",
      "Epoch 75/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0187\n",
      "Epoch 76/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 77/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 78/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0191\n",
      "Epoch 79/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0178 - val_loss: 0.0188\n",
      "Epoch 80/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 81/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 82/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0209\n",
      "Epoch 83/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0209\n",
      "Epoch 84/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0176 - val_loss: 0.0193\n",
      "Epoch 85/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0173 - val_loss: 0.0187\n",
      "Epoch 86/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 87/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0186\n",
      "Epoch 88/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0188\n",
      "Epoch 89/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0205\n",
      "Epoch 90/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0203\n",
      "Epoch 91/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0176 - val_loss: 0.0187\n",
      "Epoch 92/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 93/100\n",
      "405/405 [==============================] - 2s 6ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 94/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0187\n",
      "Epoch 95/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0196\n",
      "Epoch 96/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0190\n",
      "Epoch 97/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0172 - val_loss: 0.0187\n",
      "Epoch 98/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0174 - val_loss: 0.0186\n",
      "Epoch 99/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0173 - val_loss: 0.0187\n",
      "Epoch 100/100\n",
      "405/405 [==============================] - 2s 5ms/step - loss: 0.0175 - val_loss: 0.0187\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "# LSTM + CNN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Conv1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from pyproj import Transformer\n",
    "\n",
    "import binascii\n",
    "from shapely import wkb\n",
    "import pyproj\n",
    "\n",
    "def convert_wkb_to_coordinates(wkb_string):\n",
    "    \n",
    "    # 0단계 :Check if the value is a float\n",
    "    if isinstance(wkb_string, float):\n",
    "        return None, None\n",
    "    \n",
    "    # 1단계: 16진수 문자열을 이진 형식으로 디코딩\n",
    "    binary_string = binascii.unhexlify(wkb_string)\n",
    "\n",
    "    # 2단계: 이진 형식 파싱 \n",
    "    geometry = wkb.loads(binary_string)\n",
    "\n",
    "    # 3단계: 좌표를 위도와 경도로 변환\n",
    "    if geometry and hasattr(geometry, 'wkt'):\n",
    "        # Well-Known Text (WKT) 형식으로 변환\n",
    "        wkt = geometry.wkt\n",
    "\n",
    "        # 좌표 시스템 변환 정의\n",
    "        #!crs_from = pyproj.Proj(init='epsg:3857')\n",
    "        #!crs_to = pyproj.Proj(init='epsg:4326')\n",
    "        transformer = Transformer.from_crs(\"EPSG:3857\", \"EPSG:4326\")\n",
    "        transformer.transform(12, 12)\n",
    "\n",
    "        # 좌표 변환 수행\n",
    "        #! transformed = pyproj.transform(crs_from, crs_to, geometry.x, geometry.y)\n",
    "        transformed = Transformer.transform(transformer,geometry.x, geometry.y)\n",
    "\n",
    "        # 위도와 경도 추출\n",
    "        latitude, longitude = transformed[0], transformed[1]\n",
    "        \n",
    "        return latitude, longitude\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "\n",
    "# CSV 파일에서 데이터 로드\n",
    "data = pd.read_csv('D:\\\\장우영\\\\LOCALSEARCH\\\\DA\\\\DA\\\\data\\\\FAmerge_20230531_103345.csv', encoding='ANSI')\n",
    "\n",
    "# 특정 칼럼의 조건에 따라 데이터 필터링\n",
    "filtered_data = data[data['sog'] > 3]  # 특정 칼럼과 조건을 적절히 수정해야 합니다\n",
    "\n",
    "data= filtered_data\n",
    "\n",
    "\n",
    "# 좌표 변환 적용 및 데이터프레임 업데이트\n",
    "data[['latitude', 'longitude']] = data['geom'].apply(convert_wkb_to_coordinates).apply(pd.Series)\n",
    "\n",
    "#print(data[['latitude', 'longitude']])\n",
    "\n",
    "# \"insert_time\"을 숫자로 변환\n",
    "data['year'] = pd.to_datetime(data['insert_time']).dt.year\n",
    "data['month'] = pd.to_datetime(data['insert_time']).dt.month\n",
    "data['day'] = pd.to_datetime(data['insert_time']).dt.day\n",
    "data['hour'] = pd.to_datetime(data['insert_time']).dt.hour\n",
    "data['minute'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "data['second'] = pd.to_datetime(data['insert_time']).dt.minute\n",
    "\n",
    "\n",
    "# 특성과 타겟 변수 선택\n",
    "X = data[[\"mmsi\", \"ship_type\", \"latitude\", \"longitude\", \"cog\", \"sog\", \"year\", \"month\", \"day\", \"hour\", \"minute\", \"second\", \"풍향\", \"유향\", \"기온\", \"수온\", \"풍속\", \"유속\", \"기압\", \"습도\"]]\n",
    "\n",
    "# 각 변수에 대한 타겟 변수 선택\n",
    "y_latitude = data[[\"latitude\"]]\n",
    "y_longitude = data[[\"longitude\"]]\n",
    "y_cog = data[[\"cog\"]]\n",
    "y_sog = data[[\"sog\"]]\n",
    "\n",
    "# 데이터를 훈련 세트와 테스트 세트로 분할\n",
    "X_train, X_test, y_latitude_train, y_latitude_test, y_longitude_train, y_longitude_test, y_cog_train, y_cog_test, y_sog_train, y_sog_test = train_test_split(X, y_latitude, y_longitude, y_cog, y_sog, test_size=0.2, random_state=42)\n",
    "\n",
    "# MinMaxScaler를 사용하여 입력 특성 스케일 조정\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# LSTM에 맞게 입력 데이터 형태 변환\n",
    "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "# LSTM과 CNN을 결합한 모델 생성\n",
    "model_latitude = Sequential()\n",
    "model_longitude = Sequential()\n",
    "model_cog = Sequential()\n",
    "model_sog = Sequential()\n",
    "\n",
    "# Conv1D 레이어를 추가합니다. 1D 컨볼루션 연산을 수행하는 레이어로, 입력 데이터의 필터 수는 64개, 커널 크기는 3입니다. 활성화 함수로는 ReLU를 사용하고, 입력 형태는 X_train_reshaped의 shape[1]과 shape[2]에 해당합니다.\n",
    "model_latitude.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model_longitude.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model_cog.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "model_sog.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
    "\n",
    "# LSTM은 순환 신경망의 한 종류로, 입력 데이터에 대한 장기 의존성을 모델링하는 데 사용됩니다. 이 레이어의 뉴런 수는 64개\n",
    "model_latitude.add(LSTM(64))\n",
    "model_longitude.add(LSTM(64))\n",
    "model_cog.add(LSTM(64))\n",
    "model_sog.add(LSTM(64))\n",
    "\n",
    "# Dense 레이어를 추가합니다. 출력층으로 사용되며, 뉴런 수는 1개입니다. 각각의 모델에 대해 예측을 수행하므로 출력은 1개\n",
    "model_latitude.add(Dense(1))\n",
    "model_longitude.add(Dense(1))\n",
    "model_cog.add(Dense(1))\n",
    "model_sog.add(Dense(1))\n",
    "\n",
    "# 모델 컴파일\n",
    "model_latitude.compile(loss='mse', optimizer='adam')\n",
    "model_longitude.compile(loss='mse', optimizer='adam')\n",
    "model_cog.compile(loss='mse', optimizer='adam')\n",
    "model_sog.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# 모델 훈련\n",
    "history_latitude = model_latitude.fit(X_train_reshaped, y_latitude_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_latitude_test))\n",
    "history_longitude = model_longitude.fit(X_train_reshaped, y_longitude_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_longitude_test))\n",
    "history_cog = model_cog.fit(X_train_reshaped, y_cog_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_cog_test))\n",
    "history_sog = model_sog.fit(X_train_reshaped, y_sog_train, epochs=100, batch_size=32, validation_data=(X_test_reshaped, y_sog_test))\n",
    "\n",
    "# 모델을 사용하여 예측 수행\n",
    "y_latitude_pred = model_latitude.predict(X_test_reshaped)\n",
    "y_longitude_pred = model_longitude.predict(X_test_reshaped)\n",
    "y_cog_pred = model_cog.predict(X_test_reshaped)\n",
    "y_sog_pred = model_sog.predict(X_test_reshaped)\n",
    "\n",
    "# Convert predictions to a list\n",
    "y_latitude_pred_list = y_latitude_pred.tolist()\n",
    "y_longitude_pred_list = y_longitude_pred.tolist()\n",
    "y_cog_pred_list = y_cog_pred.tolist()\n",
    "y_sog_pred_list = y_sog_pred.tolist()\n",
    "\n",
    "# 평균 제곱 오차 계산\n",
    "mse_latitude = mean_squared_error(y_latitude_test, y_latitude_pred)\n",
    "mse_longitude = mean_squared_error(y_longitude_test, y_longitude_pred)\n",
    "mse_cog = mean_squared_error(y_cog_test, y_cog_pred)\n",
    "mse_sog = mean_squared_error(y_sog_test, y_sog_pred)\n",
    "\n",
    "print(\"Mean Squared Error - Latitude:\", mse_latitude)\n",
    "print(\"Mean Squared Error - Longitude:\", mse_longitude)\n",
    "print(\"Mean Squared Error - COG:\", mse_cog)\n",
    "print(\"Mean Squared Error - SOG:\", mse_sog)\n",
    "\n",
    "# Create the response JSON\n",
    "response = {\n",
    "    \"latitude\": y_latitude_pred_list[0][0],\n",
    "    \"longitude\": y_longitude_pred_list[0][0],\n",
    "    \"predicted_cog\": y_cog_pred_list[0][0],\n",
    "    \"predicted_sog\": y_sog_pred_list[0][0]\n",
    "}\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 모델 저장\n",
    "with open('model_latitude02.pkl', 'wb') as f:\n",
    "    pickle.dump(model_latitude, f)\n",
    "\n",
    "with open('model_longitude02.pkl', 'wb') as f:\n",
    "    pickle.dump(model_longitude, f)\n",
    "\n",
    "with open('model_cog02.pkl', 'wb') as f:\n",
    "    pickle.dump(model_cog, f)\n",
    "\n",
    "with open('model_sog02.pkl', 'wb') as f:\n",
    "    pickle.dump(model_sog, f)\n",
    "\n",
    "# 모델 불러오기\n",
    "with open('model_latitude02.pkl', 'rb') as f:\n",
    "    model_latitude = pickle.load(f)\n",
    "\n",
    "with open('model_longitude02.pkl', 'rb') as f:\n",
    "    model_longitude = pickle.load(f)\n",
    "\n",
    "with open('model_cog02.pkl', 'rb') as f:\n",
    "    model_cog = pickle.load(f)\n",
    "\n",
    "with open('model_sog02.pkl', 'rb') as f:\n",
    "    model_sog = pickle.load(f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
